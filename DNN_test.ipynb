{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import cv2 as cv\n",
    "import json\n",
    "import sys \n",
    "from skimage import exposure\n",
    "\n",
    "sys.path.insert(0, 'source')\n",
    "from nn import *\n",
    "from laploss import *\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "sys.path.insert(0, 'lib')\n",
    "from iplabs import IPLabViewer as viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN4SimBase(nn.Module):\n",
    "    def training_step(self, batch, loss_func=F.smooth_l1_loss):\n",
    "        images, labels = batch \n",
    "        out = self(images)            # Generate predictions\n",
    "        loss = loss_func(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, loss_func=F.smooth_l1_loss):\n",
    "        images, labels = batch \n",
    "        out = self(images)              # Generate predictions\n",
    "        loss = loss_func(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)     # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "        \n",
    "class CUNet(DNN4SimBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.down1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2, 2),\n",
    "                                   nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2, 2),\n",
    "                                   nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.down4 = nn.Sequential(nn.MaxPool2d(2, 2),\n",
    "                                   nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.downF = nn.Sequential(nn.MaxPool2d(2, 2),\n",
    "                                   nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2))\n",
    "        self.up1  =  nn.Sequential(nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2))\n",
    "        self.up2  =  nn.Sequential(nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2))\n",
    "        self.up3  =  nn.Sequential(nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2))\n",
    "        self.up4  =  nn.Sequential(nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.upF  =  nn.Sequential(nn.Conv2d(64, 1, kernel_size=1, stride=1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x5 = self.downF(x4)\n",
    "        x6 = self.up1(torch.cat((x4,x5), dim=1))\n",
    "        x7 = self.up2(torch.cat((x3,x6), dim=1))\n",
    "        x8 = self.up3(torch.cat((x2,x7), dim=1))\n",
    "        x9 = self.up4(torch.cat((x1,x8), dim=1))\n",
    "        xF = self.upF(x9)                 \n",
    "        return xF\n",
    "\n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, loss_func=F.smooth_l1_loss):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch, loss_func=loss_func) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam, loss_func=F.smooth_l1_loss):\n",
    "    print('Starting training')\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Running epoch {epoch} ... ', end='\\r')\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            print(f'Running epoch {epoch} ... {i/len(train_loader)*100:3.0f}%', end='\\r')\n",
    "            loss = model.training_step(batch, loss_func=loss_func)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        print(f'Running epoch {epoch} ... Done                     ', end='\\r')\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader, loss_func=loss_func)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "def accuracy_numpy(outputs, labels):\n",
    "    if len(outputs.shape) > 2:\n",
    "        outputs = outputs.squeeze()\n",
    "        labels = labels.squeeze()\n",
    "        acc = []\n",
    "        for i in range(outputs.shape[0]):\n",
    "            acc.append(ssim(outputs[i], labels[i], dynamic_range=max(outputs[i].max() - outputs[i].min(), labels[i].max() - labels[i].min())))\n",
    "        return np.mean(acc)\n",
    "    else:\n",
    "        return ssim(outputs, labels, dynamic_range=max(outputs.max() - outputs.min(), labels.max() - labels.min()))\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    return pytorch_ssim.ssim(outputs, labels)\n",
    "    \n",
    "def get_train_val(features, labels, train_ratio=0.8, batch_size=10):\n",
    "    if features.shape[0] != labels.shape[0]:\n",
    "        raise ValueError('Features and Labels are not of the same size')\n",
    "    if len(features.shape) != 3:\n",
    "        raise ValueError('Features and Labels should be 3-dimensional')\n",
    "\n",
    "    length = features.shape[0]\n",
    "    \n",
    "    if length % batch_size != 0:\n",
    "        features = features[:-(length % batch_size)]\n",
    "        labels = labels[:-(length % batch_size)]\n",
    "    \n",
    "    features = np.reshape(features, (-1, batch_size, 1, features.shape[1], features.shape[2]))\n",
    "    labels = np.reshape(labels, (-1, batch_size, 1, labels.shape[1], labels.shape[2]))\n",
    "    \n",
    "    n = int(train_ratio*features.shape[0])\n",
    "    \n",
    "    train_set = [(torch.FloatTensor(features[i]), torch.FloatTensor(labels[i])) for i in range(n)]\n",
    "    val_set = [(torch.FloatTensor(features[i]), torch.FloatTensor(labels[i])) for i in range(n, features.shape[0])]\n",
    "    return train_set, val_set\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1       [-1, 64, 1024, 1024]             640\n",
      "              ReLU-2       [-1, 64, 1024, 1024]               0\n",
      "            Conv2d-3       [-1, 64, 1024, 1024]          36,928\n",
      "              ReLU-4       [-1, 64, 1024, 1024]               0\n",
      "         MaxPool2d-5         [-1, 64, 512, 512]               0\n",
      "            Conv2d-6        [-1, 128, 512, 512]          73,856\n",
      "              ReLU-7        [-1, 128, 512, 512]               0\n",
      "            Conv2d-8        [-1, 128, 512, 512]         147,584\n",
      "              ReLU-9        [-1, 128, 512, 512]               0\n",
      "        MaxPool2d-10        [-1, 128, 256, 256]               0\n",
      "           Conv2d-11        [-1, 256, 256, 256]         295,168\n",
      "             ReLU-12        [-1, 256, 256, 256]               0\n",
      "           Conv2d-13        [-1, 256, 256, 256]         590,080\n",
      "             ReLU-14        [-1, 256, 256, 256]               0\n",
      "        MaxPool2d-15        [-1, 256, 128, 128]               0\n",
      "           Conv2d-16        [-1, 512, 128, 128]       1,180,160\n",
      "             ReLU-17        [-1, 512, 128, 128]               0\n",
      "           Conv2d-18        [-1, 512, 128, 128]       2,359,808\n",
      "             ReLU-19        [-1, 512, 128, 128]               0\n",
      "        MaxPool2d-20          [-1, 512, 64, 64]               0\n",
      "           Conv2d-21         [-1, 1024, 64, 64]       4,719,616\n",
      "             ReLU-22         [-1, 1024, 64, 64]               0\n",
      "           Conv2d-23         [-1, 1024, 64, 64]       9,438,208\n",
      "             ReLU-24         [-1, 1024, 64, 64]               0\n",
      "  ConvTranspose2d-25        [-1, 512, 128, 128]       2,097,664\n",
      "           Conv2d-26        [-1, 512, 128, 128]       4,719,104\n",
      "             ReLU-27        [-1, 512, 128, 128]               0\n",
      "           Conv2d-28        [-1, 512, 128, 128]       2,359,808\n",
      "             ReLU-29        [-1, 512, 128, 128]               0\n",
      "  ConvTranspose2d-30        [-1, 256, 256, 256]         524,544\n",
      "           Conv2d-31        [-1, 256, 256, 256]       1,179,904\n",
      "             ReLU-32        [-1, 256, 256, 256]               0\n",
      "           Conv2d-33        [-1, 256, 256, 256]         590,080\n",
      "             ReLU-34        [-1, 256, 256, 256]               0\n",
      "  ConvTranspose2d-35        [-1, 128, 512, 512]         131,200\n",
      "           Conv2d-36        [-1, 128, 512, 512]         295,040\n",
      "             ReLU-37        [-1, 128, 512, 512]               0\n",
      "           Conv2d-38        [-1, 128, 512, 512]         147,584\n",
      "             ReLU-39        [-1, 128, 512, 512]               0\n",
      "  ConvTranspose2d-40       [-1, 64, 1024, 1024]          32,832\n",
      "           Conv2d-41       [-1, 64, 1024, 1024]          73,792\n",
      "             ReLU-42       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-43       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-44       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-45        [-1, 1, 1024, 1024]              65\n",
      "================================================================\n",
      "Total params: 31,030,593\n",
      "Trainable params: 31,030,593\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.00\n",
      "Forward/backward pass size (MB): 9016.00\n",
      "Params size (MB): 118.37\n",
      "Estimated Total Size (MB): 9138.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CUNet(), (1, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(255,767))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test\n",
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "with open(f'DNN4SIM_data/features.npy', 'rb') as f:\n",
    "    features = np.load(f)\n",
    "labels = []\n",
    "with open(f'DNN4SIM_data/labels.npy', 'rb') as f:\n",
    "    labels = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1024, 1024) (900, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_ssim\n",
    "# Custom loss function combingin Smooth L1 Loss with SSIM\n",
    "def custom_loss(output, target):\n",
    "    ssim_loss = pytorch_ssim.SSIM()\n",
    "    sl1l = F.smooth_l1_loss\n",
    "    return sl1l(output, target) + 0.01 * (1 - ssim_loss(output, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline validation accuracy = 0.23830097913742065\n",
      "Train size = 80, Validation size = 20\n"
     ]
    }
   ],
   "source": [
    "def add_noise(img):\n",
    "    return img + np.random.random(img.shape)*0.2\n",
    "\n",
    "data_size = 100\n",
    "batch_size = 10\n",
    "\n",
    "dataset_noisy = add_noise(dataset[:data_size,:512,:512])\n",
    "\n",
    "train_set, val_set = get_train_val(dataset_noisy, dataset[:data_size,:512,:512], batch_size=batch_size)\n",
    "\n",
    "# Move data to GPU\n",
    "train_loader = DeviceDataLoader(train_set, get_default_device())\n",
    "val_loader = DeviceDataLoader(val_set, get_default_device())\n",
    "\n",
    "accs = []\n",
    "for im, lab in val_set:\n",
    "    accs.append(accuracy(im, lab))\n",
    "\n",
    "print(f'Baseline validation accuracy = {torch.stack(accs).mean()}')\n",
    "\n",
    "print(f'Train size = {len(train_set)*batch_size}, Validation size = {len(val_set)*batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up memory\n",
    "del dataset\n",
    "del dataset_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch [0], train_loss: 0.0206, val_loss: 0.0100, val_acc: 0.5966\n",
      "Epoch [1], train_loss: 0.0064, val_loss: 0.0034, val_acc: 0.7832\n",
      "Epoch [2], train_loss: 0.0030, val_loss: 0.0032, val_acc: 0.8237\n",
      "Epoch [3], train_loss: 0.0021, val_loss: 0.0020, val_acc: 0.8635\n",
      "Epoch [4], train_loss: 0.0017, val_loss: 0.0013, val_acc: 0.8812\n",
      "Epoch [5], train_loss: 0.0019, val_loss: 0.0011, val_acc: 0.9072\n",
      "Epoch [6], train_loss: 0.0010, val_loss: 0.0010, val_acc: 0.9165\n",
      "Epoch [7], train_loss: 0.0010, val_loss: 0.0009, val_acc: 0.9169\n",
      "Epoch [8], train_loss: 0.0009, val_loss: 0.0010, val_acc: 0.9165\n",
      "Epoch [9], train_loss: 0.0009, val_loss: 0.0009, val_acc: 0.9194\n"
     ]
    }
   ],
   "source": [
    "net = CUNet()\n",
    "history = fit(epochs=10, lr=0.001, model=net, train_loader=train_loader, val_loader=val_loader, loss_func=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57afb95ec3314b3bb402a5901ab842b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = [x['train_loss'] for x in history]\n",
    "val_loss = [x['val_loss'] for x in history]\n",
    "val_acc = [x['val_acc'] for x in history]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.subplot(122)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c1dc4a39944cfa89c696e37112fc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1d72ce1524465ca3c0f41a6bc37b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sig = 1\n",
    "view = viewer([val_set[0][1][4].numpy().squeeze(), val_set[0][0][4].numpy().squeeze(), net(val_set[0][0][4].unsqueeze(dim=0)).detach().numpy().squeeze(), cv.GaussianBlur(val_set[0][1][4].numpy().squeeze(), (0,0), sig)], title=['Original', 'Noisy', 'Net Output'], subplots=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d6b25b096a4dd9bb5e0822bf4ec826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<iplabs.IPLabViewer at 0x17669d88a88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "n=11\n",
    "viewer([dataset[n], np.fft.fftshift(10*np.log10(np.abs(np.fft.fft2(dataset[n]))))], subplots=(1,2), cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_id = 'custom_new_4'\n",
    "history = None\n",
    "with open(f'DNN4SIM_data/train_out/train_history_{loss_id}.json') as f:\n",
    "  history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0fe9e7846a4fc9bcd477c79b58bb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = [x['train_loss'] for x in history]\n",
    "val_loss = [x['val_loss'] for x in history]\n",
    "val_acc = [x['val_acc'] for x in history]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.subplot(122)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('DNN4SIM_data/data_reduced/features_1.npy')\n",
    "labels = np.load('DNN4SIM_data/data_reduced/labels_1.npy')\n",
    "wfs = np.load('DNN4SIM_data/data_reduced/wf_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[:features.shape[0]//3]\n",
    "labels = labels[:labels.shape[0]//3]\n",
    "wfs = wfs[:wfs.shape[0]//3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d249e1905b674294a6b1b76a18f3762b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rosette_512 = np.load('DNN4SIM_data/rosette_512.npy')\n",
    "rosette_1024 = np.load('DNN4SIM_data/rosette_1024.npy')\n",
    "def apply_rosette(img, rosette):\n",
    "    FT = np.fft.fftshift(np.fft.fft2(img))\n",
    "    FT[rosette == 0] = 1e-5\n",
    "    return np.real(np.fft.ifft2(np.fft.ifftshift(FT)))\n",
    "\n",
    "def apply_fft(img):\n",
    "    FT = np.abs(np.fft.fftshift(np.fft.fft2(img)))\n",
    "    FT[FT == 0] = 1e-5\n",
    "    return 10*np.log10(FT)\n",
    "\n",
    "def process_img(img):\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    return exposure.equalize_adapthist(img, clip_limit=0.1)\n",
    "\n",
    "def snr(img):\n",
    "    m = np.mean(img)\n",
    "    sd = np.std(img)\n",
    "    return np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "test_img = 'sim_test_img_2'\n",
    "\n",
    "test_feature = cv.imread(f'DNN4SIM_data/{test_img}_recons.png', cv.IMREAD_GRAYSCALE)\n",
    "test_wf = cv.imread(f'DNN4SIM_data/{test_img}_wf.png', cv.IMREAD_GRAYSCALE)\n",
    "test_label = apply_rosette(cv.imread(f'DNN4SIM_data/{test_img}.png', cv.IMREAD_GRAYSCALE), rosette_1024)\n",
    "\n",
    "#test_feature = process_img(test_feature)\n",
    "#test_wf = process_img(test_wf)\n",
    "#test_label = process_img(test_label)\n",
    "\n",
    "label_FT = apply_fft(test_label); feature_FT = apply_fft(test_feature); test_label_FT = apply_fft(test_label)\n",
    "img_list = [test_feature, test_label, feature_FT, test_label_FT]\n",
    "\n",
    "plt.close('all')\n",
    "view = viewer(img_list, subplots=(2,2), cmap='viridis', joint_zoom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUNet(\n",
       "  (down1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (down2): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (down3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (down4): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (downF): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (up1): Sequential(\n",
       "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (up2): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (up3): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (up4): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (upF): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_id = 'custom_new_4'\n",
    "model = CUNet()\n",
    "model.load_state_dict(torch.load(f'DNN4SIM_data/train_out/trained_model_{loss_id}.pt', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_output = np.squeeze(model(torch.FloatTensor(test_feature).unsqueeze(dim=0).unsqueeze(dim=0)).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82edb0c401774643ab00494d8bdb1953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72ddaeca16d461ea7e5eea2de99c6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#img_list = [test_feature[570:770, 510:710], test_label[570:770, 510:710], net_output[570:770, 510:710], test_wf[570:770, 510:710]]\n",
    "#img_list = [test_feature[580:640, 650:710], test_label[580:640, 650:710], net_output[580:640, 650:710], test_wf[580:640, 650:710]]\n",
    "\n",
    "img_list = [test_feature, test_label, net_output, test_wf]\n",
    "\n",
    "title_list = ['Reconstruction', 'Ground-Truth', 'Net Output', 'Widefield']\n",
    "plt.close('all')\n",
    "view = viewer(img_list, title=title_list, subplots=(2,2), cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUNet(\n",
       "  (down1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (down2): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (down3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (down4): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (downF): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (up1): Sequential(\n",
       "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (up2): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (up3): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (up4): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (upF): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_id = 'custom_new_4'\n",
    "model = CUNet()\n",
    "model.load_state_dict(torch.load(f'DNN4SIM_data/train_out/trained_model_{loss_id}.pt', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fft(img):\n",
    "    FT = np.abs(np.fft.fftshift(np.fft.fft2(img)))\n",
    "    FT[FT == 0] = 1e-5\n",
    "    return 10*np.log10(FT)\n",
    "def process_img(img):\n",
    "    return exposure.equalize_adapthist(normalize(img), clip_limit=0.1)\n",
    "def normalize(img):\n",
    "    return (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "def snr(img):\n",
    "    m = np.mean(img)\n",
    "    sd = np.std(img)\n",
    "    return 10*np.log10(m/sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 253\n",
    "feature = features[n]\n",
    "label = labels[n]\n",
    "wf = wfs[n]\n",
    "\n",
    "net_output = process_img(np.squeeze(model(torch.FloatTensor(feature).unsqueeze(dim=0).unsqueeze(dim=0)).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM:\tReconstruction: 0.4578\n",
      "\tNet output: \t0.7467\n",
      "\tWidefield: \t0.4679\n",
      "SNR:\tReconstruction: 1.7830\n",
      "\tNet output: \t1.7630\n",
      "\tWidefield: \t1.7906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6a1950346445efb2e1dd2c8a528adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With FT\n",
    "\n",
    "#label_FT = apply_fft(label); feature_FT = apply_fft(feature); net_output_FT = apply_fft(net_output)\n",
    "#img_list = [feature, net_output, feature_FT, net_output_FT]\n",
    "\n",
    "# For img 253\n",
    "#feature = feature[770:1024, 575:829]; label = label[770:1024, 575:829]; wf = wf[770:1024, 575:829]; net_output = net_output[770:1024, 575:829]\n",
    "\n",
    "# Without wf / without FT\n",
    "img_list = [feature, label, net_output, wf]\n",
    "\n",
    "# Stats\n",
    "print(f'SSIM:\\tReconstruction: {ssim(feature, label):.4f}\\n\\tNet output: \\t{ssim(net_output, label):.4f}\\n\\tWidefield: \\t{ssim(wf, label):.4f}')\n",
    "print(f'SNR:\\tReconstruction: {snr(feature):.4f}\\n\\tNet output: \\t{snr(net_output):.4f}\\n\\tWidefield: \\t{snr(wf):.4f}')\n",
    "\n",
    "plt.close('all')\n",
    "view = viewer(img_list, subplots=(2,2), cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Showcase Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Widefield image is not in [0,1]\n",
    "wf = wf-np.min(wf)\n",
    "# Colorize images\n",
    "feature_colorized = cv.applyColorMap((feature*255).astype(np.uint8), cv.COLORMAP_VIRIDIS)\n",
    "wf_colorized = cv.applyColorMap((wf*255).astype(np.uint8), cv.COLORMAP_VIRIDIS)\n",
    "label_colorized = cv.applyColorMap((label*255).astype(np.uint8), cv.COLORMAP_VIRIDIS)\n",
    "net_output_colorized = cv.applyColorMap((net_output*255).astype(np.uint8), cv.COLORMAP_VIRIDIS)\n",
    "\n",
    "loss_id = 'L1'\n",
    "# Save images\n",
    "cv.imwrite(f'showcase/feature_{loss_id}.png', feature_colorized)\n",
    "cv.imwrite(f'showcase/wf_{loss_id}.png', wf_colorized)\n",
    "cv.imwrite(f'showcase/label_{loss_id}.png', label_colorized)\n",
    "cv.imwrite(f'showcase/net_output_{loss_id}.png', net_output_colorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rosette tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosette_512 = np.load('DNN4SIM_data/rosette_512.npy')\n",
    "rosette_1024 = np.load('DNN4SIM_data/rosette_1024.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rosette(img, rosette):\n",
    "    FT = np.fft.fftshift(np.fft.fft2(img))\n",
    "    FT[rosette == 0] = 1e-5\n",
    "    return np.real(np.fft.ifft2(np.fft.ifftshift(FT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1c38cd165a46ce9f06e3f94aac10e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<iplabs.IPLabViewer at 0x178e8ad2e88>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = apply_rosette(label, rosette_1024)\n",
    "l = (l - np.min(l)) / (np.max(l) - np.min(l))\n",
    "l_ft = apply_fft(l)\n",
    "f = feature\n",
    "f_ft = apply_fft(f)\n",
    "plt.close('all')\n",
    "viewer([f, l, f_ft, l_ft], subplots=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS-SSIM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(output, target):\n",
    "    ssim_loss = MS_SSIM(data_range=1.0, size_average=True, channel=1)\n",
    "    sl1l = F.smooth_l1_loss\n",
    "    return 0.16 * sl1l(output, target) + 0.84 * (1 - ssim_loss(output, target))\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    return ssim(outputs, labels, data_range=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5339216589927673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5550482273101807"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "X = torch.FloatTensor(wf).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "Y = torch.FloatTensor(label).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "\n",
    "print(accuracy(X, Y).item())\n",
    "ssim_acc = pytorch_ssim.SSIM()\n",
    "ssim_acc(X, Y).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
