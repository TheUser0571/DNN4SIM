{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import cv2 as cv\n",
    "import json\n",
    "import sys \n",
    "from skimage import exposure\n",
    "import pickle\n",
    "\n",
    "sys.path.insert(0, 'source')\n",
    "from nn import *\n",
    "from laploss import *\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "sys.path.insert(0, 'lib')\n",
    "from iplabs import IPLabViewer as viewer\n",
    "\n",
    "# Print colors\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "## Index\n",
    "The interesting parts of this notebook are:\n",
    "* [Single-image analysis](#Test-img)\n",
    "* [Multi-image analysis](#Compare-different-SNR-directly)\n",
    "\n",
    "## RCAN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        padding=(kernel_size//2), bias=bias)\n",
    "\n",
    "class Upsampler(nn.Sequential):\n",
    "    def __init__(self, conv, scale, n_feat, bn=False, act=False, bias=True):\n",
    "        m = []\n",
    "        if (scale & (scale - 1)) == 0:    # Is scale = 2^n?\n",
    "            for _ in range(int(math.log(scale, 2))):\n",
    "                m.append(conv(n_feat, 4 * n_feat, 3, bias))\n",
    "                m.append(nn.PixelShuffle(2))\n",
    "                if bn: m.append(nn.BatchNorm2d(n_feat))\n",
    "                if act: m.append(act())\n",
    "        elif scale == 3:\n",
    "            m.append(conv(n_feat, 9 * n_feat, 3, bias))\n",
    "            m.append(nn.PixelShuffle(3))\n",
    "            if bn: m.append(nn.BatchNorm2d(n_feat))\n",
    "            if act: m.append(act())\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        super(Upsampler, self).__init__(*m)\n",
    "\n",
    "## Channel Attention (CA) Layer\n",
    "class CALayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(CALayer, self).__init__()\n",
    "        # global average pooling: feature --> point\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # feature channel downscale and upscale --> channel weight\n",
    "        self.conv_du = nn.Sequential(\n",
    "                nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.conv_du(y)\n",
    "        return x * y\n",
    "\n",
    "## Residual Channel Attention Block (RCAB)\n",
    "class RCAB(nn.Module):\n",
    "    def __init__(\n",
    "        self, conv, n_feat, kernel_size, reduction,\n",
    "        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
    "\n",
    "        super(RCAB, self).__init__()\n",
    "        modules_body = []\n",
    "        for i in range(2):\n",
    "            modules_body.append(conv(n_feat, n_feat, kernel_size, bias=bias))\n",
    "            if bn: modules_body.append(nn.BatchNorm2d(n_feat))\n",
    "            if i == 0: modules_body.append(act)\n",
    "        modules_body.append(CALayer(n_feat, reduction))\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x)\n",
    "        #res = self.body(x).mul(self.res_scale)\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "## Residual Group (RG)\n",
    "class ResidualGroup(nn.Module):\n",
    "    def __init__(self, conv, n_feat, kernel_size, reduction, act, res_scale, n_resblocks):\n",
    "        super(ResidualGroup, self).__init__()\n",
    "        modules_body = []\n",
    "        modules_body = [\n",
    "            RCAB(\n",
    "                conv, n_feat, kernel_size, reduction, bias=True, bn=False, act=nn.ReLU(True), res_scale=1) \\\n",
    "            for _ in range(n_resblocks)]\n",
    "        modules_body.append(conv(n_feat, n_feat, kernel_size))\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x)\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "## Residual Channel Attention Network (RCAN)\n",
    "class RCAN(DNN4SimBase):\n",
    "    def __init__(self, conv=default_conv, **args):\n",
    "        super(RCAN, self).__init__()\n",
    "        \n",
    "        n_resgroups = args.get('n_resgroups', 10)\n",
    "        n_resblocks = args.get('n_resblocks', 20)\n",
    "        n_feats = args.get('n_feats', 64)\n",
    "        kernel_size = 3\n",
    "        reduction = args.get('reduction', 16)\n",
    "        scale = 1\n",
    "        act = nn.ReLU(True)\n",
    "        \n",
    "        # define head module\n",
    "        modules_head = [conv(1, n_feats, kernel_size)]\n",
    "\n",
    "        # define body module\n",
    "        modules_body = [\n",
    "            ResidualGroup(\n",
    "                conv, n_feats, kernel_size, reduction, act=act, res_scale=1, n_resblocks=n_resblocks) \\\n",
    "            for _ in range(n_resgroups)]\n",
    "\n",
    "        modules_body.append(conv(n_feats, n_feats, kernel_size))\n",
    "\n",
    "        # define tail module\n",
    "        modules_tail = [\n",
    "            Upsampler(conv, scale, n_feats, act=False),\n",
    "            conv(n_feats, 1, kernel_size)]\n",
    "\n",
    "        self.head = nn.Sequential(*modules_head)\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "        self.tail = nn.Sequential(*modules_tail)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.head(x)\n",
    "\n",
    "        res = self.body(x)\n",
    "        res += x\n",
    "\n",
    "        x = self.tail(res)\n",
    "\n",
    "        return x \n",
    "\n",
    "    def load_state_dict(self, state_dict, strict=False):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name in own_state:\n",
    "                if isinstance(param, nn.Parameter):\n",
    "                    param = param.data\n",
    "                try:\n",
    "                    own_state[name].copy_(param)\n",
    "                except Exception:\n",
    "                    if name.find('tail') >= 0:\n",
    "                        print('Replace pre-trained upsampler to new one...')\n",
    "                    else:\n",
    "                        raise RuntimeError('While copying the parameter named {}, '\n",
    "                                           'whose dimensions in the model are {} and '\n",
    "                                           'whose dimensions in the checkpoint are {}.'\n",
    "                                           .format(name, own_state[name].size(), param.size()))\n",
    "            elif strict:\n",
    "                if name.find('tail') == -1:\n",
    "                    raise KeyError('unexpected key \"{}\" in state_dict'\n",
    "                                   .format(name))\n",
    "\n",
    "        if strict:\n",
    "            missing = set(own_state.keys()) - set(state_dict.keys())\n",
    "            if len(missing) > 0:\n",
    "                raise KeyError('missing keys in state_dict: \"{}\"'.format(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1       [-1, 64, 1024, 1024]             640\n",
      "            Conv2d-2       [-1, 64, 1024, 1024]          36,928\n",
      "              ReLU-3       [-1, 64, 1024, 1024]               0\n",
      "            Conv2d-4       [-1, 64, 1024, 1024]          36,928\n",
      " AdaptiveAvgPool2d-5             [-1, 64, 1, 1]               0\n",
      "            Conv2d-6              [-1, 4, 1, 1]             260\n",
      "              ReLU-7              [-1, 4, 1, 1]               0\n",
      "            Conv2d-8             [-1, 64, 1, 1]             320\n",
      "           Sigmoid-9             [-1, 64, 1, 1]               0\n",
      "          CALayer-10       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-11       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-12       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-13       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-14       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-15             [-1, 64, 1, 1]               0\n",
      "           Conv2d-16              [-1, 4, 1, 1]             260\n",
      "             ReLU-17              [-1, 4, 1, 1]               0\n",
      "           Conv2d-18             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-19             [-1, 64, 1, 1]               0\n",
      "          CALayer-20       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-21       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-22       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-23       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-24       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-25             [-1, 64, 1, 1]               0\n",
      "           Conv2d-26              [-1, 4, 1, 1]             260\n",
      "             ReLU-27              [-1, 4, 1, 1]               0\n",
      "           Conv2d-28             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-29             [-1, 64, 1, 1]               0\n",
      "          CALayer-30       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-31       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-32       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-33       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-34       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-35             [-1, 64, 1, 1]               0\n",
      "           Conv2d-36              [-1, 4, 1, 1]             260\n",
      "             ReLU-37              [-1, 4, 1, 1]               0\n",
      "           Conv2d-38             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-39             [-1, 64, 1, 1]               0\n",
      "          CALayer-40       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-41       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-42       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-43       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-44       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-45             [-1, 64, 1, 1]               0\n",
      "           Conv2d-46              [-1, 4, 1, 1]             260\n",
      "             ReLU-47              [-1, 4, 1, 1]               0\n",
      "           Conv2d-48             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-49             [-1, 64, 1, 1]               0\n",
      "          CALayer-50       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-51       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-52       [-1, 64, 1024, 1024]          36,928\n",
      "    ResidualGroup-53       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-54       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-55       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-56       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-57             [-1, 64, 1, 1]               0\n",
      "           Conv2d-58              [-1, 4, 1, 1]             260\n",
      "             ReLU-59              [-1, 4, 1, 1]               0\n",
      "           Conv2d-60             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-61             [-1, 64, 1, 1]               0\n",
      "          CALayer-62       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-63       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-64       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-65       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-66       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-67             [-1, 64, 1, 1]               0\n",
      "           Conv2d-68              [-1, 4, 1, 1]             260\n",
      "             ReLU-69              [-1, 4, 1, 1]               0\n",
      "           Conv2d-70             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-71             [-1, 64, 1, 1]               0\n",
      "          CALayer-72       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-73       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-74       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-75       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-76       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-77             [-1, 64, 1, 1]               0\n",
      "           Conv2d-78              [-1, 4, 1, 1]             260\n",
      "             ReLU-79              [-1, 4, 1, 1]               0\n",
      "           Conv2d-80             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-81             [-1, 64, 1, 1]               0\n",
      "          CALayer-82       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-83       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-84       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-85       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-86       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-87             [-1, 64, 1, 1]               0\n",
      "           Conv2d-88              [-1, 4, 1, 1]             260\n",
      "             ReLU-89              [-1, 4, 1, 1]               0\n",
      "           Conv2d-90             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-91             [-1, 64, 1, 1]               0\n",
      "          CALayer-92       [-1, 64, 1024, 1024]               0\n",
      "             RCAB-93       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-94       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-95       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-96       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-97             [-1, 64, 1, 1]               0\n",
      "           Conv2d-98              [-1, 4, 1, 1]             260\n",
      "             ReLU-99              [-1, 4, 1, 1]               0\n",
      "          Conv2d-100             [-1, 64, 1, 1]             320\n",
      "         Sigmoid-101             [-1, 64, 1, 1]               0\n",
      "         CALayer-102       [-1, 64, 1024, 1024]               0\n",
      "            RCAB-103       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-104       [-1, 64, 1024, 1024]          36,928\n",
      "   ResidualGroup-105       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-106       [-1, 64, 1024, 1024]          36,928\n",
      "            ReLU-107       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-108       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-109             [-1, 64, 1, 1]               0\n",
      "          Conv2d-110              [-1, 4, 1, 1]             260\n",
      "            ReLU-111              [-1, 4, 1, 1]               0\n",
      "          Conv2d-112             [-1, 64, 1, 1]             320\n",
      "         Sigmoid-113             [-1, 64, 1, 1]               0\n",
      "         CALayer-114       [-1, 64, 1024, 1024]               0\n",
      "            RCAB-115       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-116       [-1, 64, 1024, 1024]          36,928\n",
      "            ReLU-117       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-118       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-119             [-1, 64, 1, 1]               0\n",
      "          Conv2d-120              [-1, 4, 1, 1]             260\n",
      "            ReLU-121              [-1, 4, 1, 1]               0\n",
      "          Conv2d-122             [-1, 64, 1, 1]             320\n",
      "         Sigmoid-123             [-1, 64, 1, 1]               0\n",
      "         CALayer-124       [-1, 64, 1024, 1024]               0\n",
      "            RCAB-125       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-126       [-1, 64, 1024, 1024]          36,928\n",
      "            ReLU-127       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-128       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-129             [-1, 64, 1, 1]               0\n",
      "          Conv2d-130              [-1, 4, 1, 1]             260\n",
      "            ReLU-131              [-1, 4, 1, 1]               0\n",
      "          Conv2d-132             [-1, 64, 1, 1]             320\n",
      "         Sigmoid-133             [-1, 64, 1, 1]               0\n",
      "         CALayer-134       [-1, 64, 1024, 1024]               0\n",
      "            RCAB-135       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-136       [-1, 64, 1024, 1024]          36,928\n",
      "            ReLU-137       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-138       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-139             [-1, 64, 1, 1]               0\n",
      "          Conv2d-140              [-1, 4, 1, 1]             260\n",
      "            ReLU-141              [-1, 4, 1, 1]               0\n",
      "          Conv2d-142             [-1, 64, 1, 1]             320\n",
      "         Sigmoid-143             [-1, 64, 1, 1]               0\n",
      "         CALayer-144       [-1, 64, 1024, 1024]               0\n",
      "            RCAB-145       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-146       [-1, 64, 1024, 1024]          36,928\n",
      "            ReLU-147       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-148       [-1, 64, 1024, 1024]          36,928\n",
      "AdaptiveAvgPool2d-149             [-1, 64, 1, 1]               0\n",
      "          Conv2d-150              [-1, 4, 1, 1]             260\n",
      "            ReLU-151              [-1, 4, 1, 1]               0\n",
      "          Conv2d-152             [-1, 64, 1, 1]             320\n",
      "         Sigmoid-153             [-1, 64, 1, 1]               0\n",
      "         CALayer-154       [-1, 64, 1024, 1024]               0\n",
      "            RCAB-155       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-156       [-1, 64, 1024, 1024]          36,928\n",
      "   ResidualGroup-157       [-1, 64, 1024, 1024]               0\n",
      "          Conv2d-158       [-1, 64, 1024, 1024]          36,928\n",
      "          Conv2d-159        [-1, 1, 1024, 1024]             577\n",
      "================================================================\n",
      "Total params: 1,265,469\n",
      "Trainable params: 1,265,469\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.00\n",
      "Forward/backward pass size (MB): 9736.02\n",
      "Params size (MB): 4.83\n",
      "Estimated Total Size (MB): 9744.85\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kay-1\\google drive\\dnn4sim\\env\\lib\\site-packages\\torchsummary\\torchsummary.py:93: RuntimeWarning: overflow encountered in long_scalars\n",
      "  total_output += np.prod(summary[layer][\"output_shape\"])\n"
     ]
    }
   ],
   "source": [
    "summary(RCAN(n_feats=64, n_resgroups=3, n_resblocks=5, reduction=16), (1, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RCAN(n_feats=16)\n",
    "feat = torch.FloatTensor(np.ones((1,1,10,10)))\n",
    "model(feat).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN4SimBase(nn.Module):\n",
    "    def training_step(self, batch, loss_func=F.smooth_l1_loss):\n",
    "        images, labels = batch \n",
    "        out = self(images)            # Generate predictions\n",
    "        loss = loss_func(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, loss_func=F.smooth_l1_loss):\n",
    "        images, labels = batch \n",
    "        out = self(images)              # Generate predictions\n",
    "        loss = loss_func(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)     # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "        \n",
    "class CUNet(DNN4SimBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.down1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2, 2),\n",
    "                                   nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2, 2),\n",
    "                                   nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.down4 = nn.Sequential(nn.MaxPool2d(2, 2),\n",
    "                                   nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.downF = nn.Sequential(nn.MaxPool2d(2, 2),\n",
    "                                   nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2))\n",
    "        self.up1  =  nn.Sequential(nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2))\n",
    "        self.up2  =  nn.Sequential(nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2))\n",
    "        self.up3  =  nn.Sequential(nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2))\n",
    "        self.up4  =  nn.Sequential(nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=(1,1), padding_mode='reflect'),\n",
    "                                   nn.ReLU())\n",
    "        self.upF  =  nn.Sequential(nn.Conv2d(64, 1, kernel_size=1, stride=1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x5 = self.downF(x4)\n",
    "        x6 = self.up1(torch.cat((x4,x5), dim=1))\n",
    "        x7 = self.up2(torch.cat((x3,x6), dim=1))\n",
    "        x8 = self.up3(torch.cat((x2,x7), dim=1))\n",
    "        x9 = self.up4(torch.cat((x1,x8), dim=1))\n",
    "        xF = self.upF(x9)                 \n",
    "        return xF\n",
    "\n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, loss_func=F.smooth_l1_loss):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch, loss_func=loss_func) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam, loss_func=F.smooth_l1_loss):\n",
    "    print('Starting training')\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Running epoch {epoch} ... ', end='\\r')\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            print(f'Running epoch {epoch} ... {i/len(train_loader)*100:3.0f}%', end='\\r')\n",
    "            loss = model.training_step(batch, loss_func=loss_func)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        print(f'Running epoch {epoch} ... Done                     ', end='\\r')\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader, loss_func=loss_func)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "def accuracy_numpy(outputs, labels):\n",
    "    if len(outputs.shape) > 2:\n",
    "        outputs = outputs.squeeze()\n",
    "        labels = labels.squeeze()\n",
    "        acc = []\n",
    "        for i in range(outputs.shape[0]):\n",
    "            acc.append(ssim(outputs[i], labels[i], dynamic_range=max(outputs[i].max() - outputs[i].min(), labels[i].max() - labels[i].min())))\n",
    "        return np.mean(acc)\n",
    "    else:\n",
    "        return ssim(outputs, labels, dynamic_range=max(outputs.max() - outputs.min(), labels.max() - labels.min()))\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    return pytorch_ssim.ssim(outputs, labels)\n",
    "    \n",
    "def get_train_val(features, labels, train_ratio=0.8, batch_size=10):\n",
    "    if features.shape[0] != labels.shape[0]:\n",
    "        raise ValueError('Features and Labels are not of the same size')\n",
    "    if len(features.shape) != 3:\n",
    "        raise ValueError('Features and Labels should be 3-dimensional')\n",
    "\n",
    "    length = features.shape[0]\n",
    "    \n",
    "    if length % batch_size != 0:\n",
    "        features = features[:-(length % batch_size)]\n",
    "        labels = labels[:-(length % batch_size)]\n",
    "    \n",
    "    features = np.reshape(features, (-1, batch_size, 1, features.shape[1], features.shape[2]))\n",
    "    labels = np.reshape(labels, (-1, batch_size, 1, labels.shape[1], labels.shape[2]))\n",
    "    print(f'Data size: {len(features), features[0].shape[0], features[0].shape[1], features[0].shape[2], features[0].shape[3]}')\n",
    "\n",
    "    n = int(train_ratio*features.shape[0])\n",
    "    \n",
    "    train_set = [(torch.FloatTensor(features[i]), torch.FloatTensor(labels[i])) for i in range(n)]\n",
    "    val_set = [(torch.FloatTensor(features[i]), torch.FloatTensor(labels[i])) for i in range(n, features.shape[0])]\n",
    "    print(f'Train length: {len(train_set)}\\nValidation length: {len(val_set)}')\n",
    "    return train_set, val_set\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1       [-1, 64, 1024, 1024]             640\n",
      "              ReLU-2       [-1, 64, 1024, 1024]               0\n",
      "            Conv2d-3       [-1, 64, 1024, 1024]          36,928\n",
      "              ReLU-4       [-1, 64, 1024, 1024]               0\n",
      "         MaxPool2d-5         [-1, 64, 512, 512]               0\n",
      "            Conv2d-6        [-1, 128, 512, 512]          73,856\n",
      "              ReLU-7        [-1, 128, 512, 512]               0\n",
      "            Conv2d-8        [-1, 128, 512, 512]         147,584\n",
      "              ReLU-9        [-1, 128, 512, 512]               0\n",
      "        MaxPool2d-10        [-1, 128, 256, 256]               0\n",
      "           Conv2d-11        [-1, 256, 256, 256]         295,168\n",
      "             ReLU-12        [-1, 256, 256, 256]               0\n",
      "           Conv2d-13        [-1, 256, 256, 256]         590,080\n",
      "             ReLU-14        [-1, 256, 256, 256]               0\n",
      "        MaxPool2d-15        [-1, 256, 128, 128]               0\n",
      "           Conv2d-16        [-1, 512, 128, 128]       1,180,160\n",
      "             ReLU-17        [-1, 512, 128, 128]               0\n",
      "           Conv2d-18        [-1, 512, 128, 128]       2,359,808\n",
      "             ReLU-19        [-1, 512, 128, 128]               0\n",
      "        MaxPool2d-20          [-1, 512, 64, 64]               0\n",
      "           Conv2d-21         [-1, 1024, 64, 64]       4,719,616\n",
      "             ReLU-22         [-1, 1024, 64, 64]               0\n",
      "           Conv2d-23         [-1, 1024, 64, 64]       9,438,208\n",
      "             ReLU-24         [-1, 1024, 64, 64]               0\n",
      "  ConvTranspose2d-25        [-1, 512, 128, 128]       2,097,664\n",
      "           Conv2d-26        [-1, 512, 128, 128]       4,719,104\n",
      "             ReLU-27        [-1, 512, 128, 128]               0\n",
      "           Conv2d-28        [-1, 512, 128, 128]       2,359,808\n",
      "             ReLU-29        [-1, 512, 128, 128]               0\n",
      "  ConvTranspose2d-30        [-1, 256, 256, 256]         524,544\n",
      "           Conv2d-31        [-1, 256, 256, 256]       1,179,904\n",
      "             ReLU-32        [-1, 256, 256, 256]               0\n",
      "           Conv2d-33        [-1, 256, 256, 256]         590,080\n",
      "             ReLU-34        [-1, 256, 256, 256]               0\n",
      "  ConvTranspose2d-35        [-1, 128, 512, 512]         131,200\n",
      "           Conv2d-36        [-1, 128, 512, 512]         295,040\n",
      "             ReLU-37        [-1, 128, 512, 512]               0\n",
      "           Conv2d-38        [-1, 128, 512, 512]         147,584\n",
      "             ReLU-39        [-1, 128, 512, 512]               0\n",
      "  ConvTranspose2d-40       [-1, 64, 1024, 1024]          32,832\n",
      "           Conv2d-41       [-1, 64, 1024, 1024]          73,792\n",
      "             ReLU-42       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-43       [-1, 64, 1024, 1024]          36,928\n",
      "             ReLU-44       [-1, 64, 1024, 1024]               0\n",
      "           Conv2d-45        [-1, 1, 1024, 1024]              65\n",
      "================================================================\n",
      "Total params: 31,030,593\n",
      "Trainable params: 31,030,593\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.00\n",
      "Forward/backward pass size (MB): 9016.00\n",
      "Params size (MB): 118.37\n",
      "Estimated Total Size (MB): 9138.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CUNet(), (1, 1024, 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test\n",
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "with open(f'DNN4SIM_data/features.npy', 'rb') as f:\n",
    "    features = np.load(f)\n",
    "labels = []\n",
    "with open(f'DNN4SIM_data/labels.npy', 'rb') as f:\n",
    "    labels = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1024, 1024) (900, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_ssim\n",
    "# Custom loss function combingin Smooth L1 Loss with SSIM\n",
    "def custom_loss(output, target):\n",
    "    ssim_loss = pytorch_ssim.SSIM()\n",
    "    sl1l = F.smooth_l1_loss\n",
    "    return sl1l(output, target) + 0.01 * (1 - ssim_loss(output, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline validation accuracy = 0.23830097913742065\n",
      "Train size = 80, Validation size = 20\n"
     ]
    }
   ],
   "source": [
    "def add_noise(img):\n",
    "    return img + np.random.random(img.shape)*0.2\n",
    "\n",
    "data_size = 100\n",
    "batch_size = 10\n",
    "\n",
    "dataset_noisy = add_noise(dataset[:data_size,:512,:512])\n",
    "\n",
    "train_set, val_set = get_train_val(dataset_noisy, dataset[:data_size,:512,:512], batch_size=batch_size)\n",
    "\n",
    "# Move data to GPU\n",
    "train_loader = DeviceDataLoader(train_set, get_default_device())\n",
    "val_loader = DeviceDataLoader(val_set, get_default_device())\n",
    "\n",
    "accs = []\n",
    "for im, lab in val_set:\n",
    "    accs.append(accuracy(im, lab))\n",
    "\n",
    "print(f'Baseline validation accuracy = {torch.stack(accs).mean()}')\n",
    "\n",
    "print(f'Train size = {len(train_set)*batch_size}, Validation size = {len(val_set)*batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up memory\n",
    "del dataset\n",
    "del dataset_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patchify test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 1024])\n",
      "torch.Size([256, 64, 64])\n",
      "torch.Size([1, 1024, 1024])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f607256fa01f4d5d9595b542f8d92b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a2e9ec5a914ac2a23765b8bc458118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a0d8d0df4e4885b7f61eeca74ee1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a844911f29b480e8dbb20ccccf65e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<iplabs.IPLabViewer at 0x1d4b6bb19c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = 'sim_test_img_3'\n",
    "test_img_2 = 'sim_test_img_4'\n",
    "\n",
    "\n",
    "test_label = torch.FloatTensor(cv.imread(f'DNN4SIM_data/{test_img}.png', cv.IMREAD_GRAYSCALE)).unsqueeze(dim=0)\n",
    "print(np.shape(test_label))\n",
    "\n",
    "class patchify(nn.Module):\n",
    "    def __init__(self, patches=256):\n",
    "        super(patchify, self).__init__()\n",
    "        self.patches = patches\n",
    "        n = math.sqrt(self.patches)\n",
    "        if not n.is_integer():\n",
    "            raise AssertionError('patches should be the square of an integer.')\n",
    "        self.n = int(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.shape[1] % self.n != 0 or x.shape[2] % self.n != 0:\n",
    "            raise AssertionError(f'Could not devide the image with size {img.shape} into {self.n} patches.')\n",
    "        w = x.shape[2] // self.n\n",
    "        h = x.shape[1] // self.n\n",
    "        output = torch.empty((self.patches, h, w), dtype=torch.float)\n",
    "        img = x.squeeze()\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                output[i*self.n + j] = img[i*h:(i+1)*h, j*w:(j+1)*w]\n",
    "        return output\n",
    "\n",
    "class depatchify(nn.Module):\n",
    "    def __init__(self, patches=256):\n",
    "        super(depatchify, self).__init__()\n",
    "        self.patches = patches\n",
    "        n = math.sqrt(patches)\n",
    "        if not n.is_integer():\n",
    "            raise AssertionError('patches should be the square of an integer.')\n",
    "        self.n = int(n)\n",
    "    \n",
    "    def forward(self, patch_list):\n",
    "        h = patch_list.shape[1]\n",
    "        w = patch_list.shape[2]\n",
    "        \n",
    "        output = torch.empty((1, h*self.n, w*self.n), dtype=torch.float)\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                output[0, i*h:(i+1)*h, j*w:(j+1)*w] = patch_list[i*self.n + j]\n",
    "        return output\n",
    "    \n",
    "p_func = patchify(patches=256)\n",
    "p = p_func(test_label)\n",
    "\n",
    "print(p.shape)\n",
    "dp_func = depatchify(patches=256)\n",
    "dp = dp_func(p)\n",
    "print(dp.shape)\n",
    "p = [k.squeeze().numpy() for k in p]\n",
    "plt.close('all')\n",
    "viewer(p, title='Patchified', subplots=(4,4))\n",
    "viewer([test_label.squeeze().numpy(), dp.squeeze().numpy()], title=['Original', 'Depatchified'], subplots=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.ones((5,5))\n",
    "t = np.expand_dims(t, axis=0)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch [0], train_loss: 0.0206, val_loss: 0.0100, val_acc: 0.5966\n",
      "Epoch [1], train_loss: 0.0064, val_loss: 0.0034, val_acc: 0.7832\n",
      "Epoch [2], train_loss: 0.0030, val_loss: 0.0032, val_acc: 0.8237\n",
      "Epoch [3], train_loss: 0.0021, val_loss: 0.0020, val_acc: 0.8635\n",
      "Epoch [4], train_loss: 0.0017, val_loss: 0.0013, val_acc: 0.8812\n",
      "Epoch [5], train_loss: 0.0019, val_loss: 0.0011, val_acc: 0.9072\n",
      "Epoch [6], train_loss: 0.0010, val_loss: 0.0010, val_acc: 0.9165\n",
      "Epoch [7], train_loss: 0.0010, val_loss: 0.0009, val_acc: 0.9169\n",
      "Epoch [8], train_loss: 0.0009, val_loss: 0.0010, val_acc: 0.9165\n",
      "Epoch [9], train_loss: 0.0009, val_loss: 0.0009, val_acc: 0.9194\n"
     ]
    }
   ],
   "source": [
    "net = CUNet()\n",
    "history = fit(epochs=10, lr=0.001, model=net, train_loader=train_loader, val_loader=val_loader, loss_func=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57afb95ec3314b3bb402a5901ab842b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = [x['train_loss'] for x in history]\n",
    "val_loss = [x['val_loss'] for x in history]\n",
    "val_acc = [x['val_acc'] for x in history]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.subplot(122)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c1dc4a39944cfa89c696e37112fc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1d72ce1524465ca3c0f41a6bc37b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sig = 1\n",
    "view = viewer([val_set[0][1][4].numpy().squeeze(), val_set[0][0][4].numpy().squeeze(), net(val_set[0][0][4].unsqueeze(dim=0)).detach().numpy().squeeze(), cv.GaussianBlur(val_set[0][1][4].numpy().squeeze(), (0,0), sig)], title=['Original', 'Noisy', 'Net Output'], subplots=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d6b25b096a4dd9bb5e0822bf4ec826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<iplabs.IPLabViewer at 0x17669d88a88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "n=11\n",
    "viewer([dataset[n], np.fft.fftshift(10*np.log10(np.abs(np.fft.fft2(dataset[n]))))], subplots=(1,2), cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfa1273765042dc9cd813d5ae55c44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_id = 'snrMIX_RCAN_custom_16_84'\n",
    "history = None\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "for i in range(1,5):\n",
    "    with open(f'DNN4SIM_data/train_out/train_history_{loss_id}_{i}.json') as f:\n",
    "        history = json.load(f)\n",
    "    train_loss.append([x['train_loss'] for x in history])\n",
    "    val_loss.append([x['val_loss'] for x in history])\n",
    "    val_acc.append([x['val_acc'] for x in history])\n",
    "# Flatten lists\n",
    "train_loss = [x for y in train_loss for x in y]\n",
    "val_loss = [x for y in val_loss for x in y]\n",
    "val_acc = [x for y in val_acc for x in y]\n",
    "train_loss = train_loss[:80]\n",
    "val_loss = val_loss[:80]\n",
    "val_acc = val_acc[:80]\n",
    "# Display\n",
    "plt.figure(figsize=(3,2.5))\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['training loss', 'validation loss']); plt.title('Training history'); plt.xlabel('Training epoch')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f'DNN4SIM_data/results_images/train_hist_{loss_id.split(\"_\")[0]}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 'snr10'\n",
    "features = np.load(f'DNN4SIM_data/features_{ID}_1.npy')\n",
    "labels = np.load(f'DNN4SIM_data/labels_1.npy')\n",
    "wfs = np.load(f'DNN4SIM_data/wf_{ID}_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[:features.shape[0]//3]\n",
    "labels = labels[:labels.shape[0]//3]\n",
    "wfs = wfs[:wfs.shape[0]//3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test img\n",
    "Analyze the DNN performance on the different test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosette_512 = np.load('DNN4SIM_data/rosette_512.npy')\n",
    "rosette_1024 = np.load('DNN4SIM_data/rosette_1024.npy')\n",
    "\n",
    "# Masks the FT of the ground-truth images to simulate a perfect SIM reconstruction\n",
    "def apply_rosette(img, rosette, sigma=10, border=10):\n",
    "    FT = np.fft.fftshift(np.fft.fft2(img))\n",
    "    FT[rosette == 0] = 1e-5\n",
    "    return np.real(np.fft.ifft2(np.fft.ifftshift(FT)))\n",
    "\n",
    "# Returns the FT in dB\n",
    "def apply_fft(img):\n",
    "    FT = np.abs(np.fft.fftshift(np.fft.fft2(img)))\n",
    "    FT[FT == 0] = 1e-5\n",
    "    return 10*np.log10(FT)\n",
    "\n",
    "# Normalizes an image to mean=0, std=1\n",
    "def process_img(img):\n",
    "    return (img - np.mean(img)) / np.std(img)\n",
    "\n",
    "# Rescales the image to [0,1], changing the lim changes the brightness\n",
    "def rescale_img(img, lim=1.0):\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    img[img > lim] = lim\n",
    "    img = img * (1/lim)\n",
    "    return img.astype(np.float64)\n",
    "\n",
    "# Calculates the SNR of an image\n",
    "def snr(img):\n",
    "    m = np.mean(img)\n",
    "    sd = np.std(img)\n",
    "    return 10*np.log10(m/sd)\n",
    "\n",
    "# Calculates the PSNR between two images\n",
    "def PSNR(img1, img2, mask=None):\n",
    "    if mask is None:\n",
    "        return 20*np.log10(np.max(img2)/np.sqrt(np.mean((img1-img2)**2)))\n",
    "    else:\n",
    "        m = mask==255\n",
    "        return 20*np.log10(np.max(img2[m])/np.sqrt(np.mean((img1[m]-img2[m])**2)))\n",
    "\n",
    "# Histogram equalization\n",
    "def stretch_contrast(img, c=0.03):\n",
    "    return exposure.equalize_adapthist(img, clip_limit=c)\n",
    "\n",
    "# Computes the Fourier Ring/Shell Correlation of two 2-D images \n",
    "def compute_frc(image_1: np.ndarray, image_2: np.ndarray, bin_width: int = 2.0):\n",
    "    image_1 = image_1 / np.sum(image_1)\n",
    "    image_2 = image_2 / np.sum(image_2)\n",
    "    f1, f2 = np.fft.fft2(image_1), np.fft.fft2(image_2)\n",
    "    af1f2 = np.real(f1 * np.conj(f2))\n",
    "    af1_2, af2_2 = np.abs(f1)**2, np.abs(f2)**2\n",
    "    nx, ny = af1f2.shape\n",
    "    x = np.arange(-np.floor(nx / 2.0), np.ceil(nx / 2.0))\n",
    "    y = np.arange(-np.floor(ny / 2.0), np.ceil(ny / 2.0))\n",
    "    distances = list()\n",
    "    wf1f2 = list()\n",
    "    wf1 = list()\n",
    "    wf2 = list()\n",
    "    for xi, yi in np.array(np.meshgrid(x,y)).T.reshape(-1, 2):\n",
    "        distances.append(np.sqrt(xi**2 + xi**2))\n",
    "        xi = int(xi)\n",
    "        yi = int(yi)\n",
    "        wf1f2.append(af1f2[xi, yi])\n",
    "        wf1.append(af1_2[xi, yi])\n",
    "        wf2.append(af2_2[xi, yi])\n",
    "\n",
    "    bins = np.arange(0, np.sqrt((nx//2)**2 + (ny//2)**2), bin_width)\n",
    "    f1f2_r, bin_edges = np.histogram(distances,\n",
    "        bins=bins,\n",
    "        weights=wf1f2\n",
    "    )\n",
    "    f12_r, bin_edges = np.histogram(\n",
    "        distances,\n",
    "        bins=bins,\n",
    "        weights=wf1\n",
    "    )\n",
    "    f22_r, bin_edges = np.histogram(\n",
    "        distances,\n",
    "        bins=bins,\n",
    "        weights=wf2\n",
    "    )\n",
    "    density = np.zeros(len(f1f2_r))\n",
    "    mask = np.logical_and(f12_r!=0, f22_r!=0)\n",
    "    density[mask] = f1f2_r[mask] / np.sqrt(f12_r[mask] * f22_r[mask])\n",
    "    density[density < 0] = 0\n",
    "    # Moving average for better visualization\n",
    "    density = np.convolve(density, np.ones(10)/10, mode='valid')\n",
    "    # return (density, np.where(density < 0.8)[0][0] / len(density))\n",
    "    return (density, sum(density) / len(density))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loads the test image with the specified SNR value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95910c4834424173835110f1f5d8ccc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78568c9085c14bcf94a2e628d45856fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify test image\n",
    "test_img = 'sim_test_img_5'\n",
    "# Specify SNR\n",
    "test_img_snr = '10'\n",
    "rosette = rosette_1024\n",
    "\n",
    "# Load images\n",
    "test_feature = rescale_img(cv.imread(f'DNN4SIM_data/{test_img}_recons_snr{test_img_snr}.png', cv.IMREAD_GRAYSCALE))\n",
    "test_wf = rescale_img(cv.imread(f'DNN4SIM_data/{test_img}_wf_snr{test_img_snr}.png', cv.IMREAD_GRAYSCALE))\n",
    "test_orig = cv.imread(f'DNN4SIM_data/{test_img}.png', cv.IMREAD_GRAYSCALE)\n",
    "test_label = rescale_img(apply_rosette(test_orig, rosette))\n",
    "\n",
    "# Normalize images\n",
    "test_feature_processed = process_img(test_feature)\n",
    "test_wf_processed = process_img(test_wf)\n",
    "test_label_processed = process_img(test_label)\n",
    "\n",
    "# Generate Fourier transforms\n",
    "label_FT = apply_fft(test_label); feature_FT = apply_fft(test_feature); wf_FT = apply_fft(test_wf)\n",
    "img_list = [test_feature, test_label, test_wf, feature_FT, label_FT, wf_FT]\n",
    "\n",
    "# Visual check\n",
    "plt.close('all')\n",
    "view = viewer(img_list, subplots=(2,3), cmap='viridis', joint_zoom=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loads the specified DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RCAN(\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (0): ResidualGroup(\n",
       "      (body): Sequential(\n",
       "        (0): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualGroup(\n",
       "      (body): Sequential(\n",
       "        (0): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualGroup(\n",
       "      (body): Sequential(\n",
       "        (0): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (tail): Sequential(\n",
       "    (0): Upsampler()\n",
       "    (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNN name\n",
    "loss_id = 'snrMIX3_RCAN_custom_16_84_4'\n",
    "structure = 'RCAN' # 'Unet'\n",
    "\n",
    "model = None\n",
    "if structure == 'RCAN':\n",
    "    model = RCAN(n_feats=64, n_resgroups=3, n_resblocks=5, reduction=16)\n",
    "else:\n",
    "    model = CUNet()\n",
    "\n",
    "model.load_state_dict(torch.load(f'DNN4SIM_data/train_out/trained_model_{loss_id}.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "#summary(model, (1,1024,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the DNN output\n",
    "net_output = rescale_img(np.squeeze(model(torch.FloatTensor(test_feature_processed).unsqueeze(dim=0).unsqueeze(dim=0)).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM:\tReconstruction: 0.3732\n",
      "\tNet output: \t0.8549\n",
      "\tWidefield: \t0.4497\n",
      "PSNR:\tReconstruction: 12.5647\n",
      "\tNet output: \t21.3279\n",
      "\tWidefield: \t14.4241\n",
      "FRC:\tReconstruction: 0.2351\n",
      "\tNet output: \t0.4313\n",
      "\tWidefield: \t0.2661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c8eb0c67044f80a31a436360298f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198230b7c983444b8c601ab84b2ce5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify zoom region\n",
    "x1=0;y1=0;x2=1024;y2=1024 # Full image\n",
    "\n",
    "#x1=633;y1=863;x2=783;y2=1013 # test_img_3_cross\n",
    "#x1=9;y1=890;x2=138;y2=1019 # test_img_3_circle\n",
    "\n",
    "#x1=606;y1=272;x2=756;y2=422 # test_img_2\n",
    "x1=360;y1=660;x2=510;y2=810 # test_img_4\n",
    "\n",
    "img_list = [test_label[y1:y2, x1:x2], test_wf[y1:y2, x1:x2], test_feature[y1:y2, x1:x2], net_output[y1:y2, x1:x2]]\n",
    "\n",
    "# Print metrics\n",
    "print(f'SSIM:\\tReconstruction: {ssim(test_feature, test_label):.4f}\\n\\tNet output: \\t{ssim(net_output, test_label):.4f}\\n\\tWidefield: \\t{ssim(test_wf, test_label):.4f}')\n",
    "print(f'PSNR:\\tReconstruction: {PSNR(test_feature, test_label):.4f}\\n\\tNet output: \\t{PSNR(net_output, test_label):.4f}\\n\\tWidefield: \\t{PSNR(test_wf, test_label):.4f}')\n",
    "print(f'FRC:\\tReconstruction: {compute_frc(test_feature, test_label)[1]:.4f}\\n\\tNet output: \\t{compute_frc(net_output, test_label)[1]:.4f}\\n\\tWidefield: \\t{compute_frc(test_wf, test_label)[1]:.4f}')\n",
    "\n",
    "# Visual comparison\n",
    "title_list = ['Reconstruction', 'Ground-Truth', 'Net Output', 'Widefield']\n",
    "plt.close('all')\n",
    "view = viewer(img_list, title=title_list, subplots=(2,2), cmap='viridis', joint_zoom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03a65b9c3b044c886db6b3655a50bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generates the intensity profile along a given line\n",
    "def get_line(img, p1, p2):\n",
    "    y0, x0 = p1\n",
    "    y1, x1 = p2\n",
    "    n = int(np.sqrt((y1-y0)**2 + (x1-x0)**2))\n",
    "    x, y = np.linspace(x0, x1, n), np.linspace(y0, y1, n)\n",
    "    return img[y.astype(np.int), x.astype(np.int)]\n",
    "\n",
    "# Specify the line\n",
    "p1 = (920, 640); p2 = (920, 800) # horizontal over cross and thin lines\n",
    "#p1 = (1008, 75); p2 = (958, 116) # ascending diagonal of smallest circle\n",
    "\n",
    "# Display the intensity profiles\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.title(title_list[i])\n",
    "    plt.plot(get_line(img_list[i], p1, p2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d28d737e3a47068eb93e8704b71ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5599413679274036\n"
     ]
    }
   ],
   "source": [
    "# Plot the FRC graph\n",
    "frc = compute_frc(net_output, test_label)\n",
    "plt.figure()\n",
    "plt.plot(frc[0])\n",
    "plt.show()\n",
    "print(frc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 3 cells are test image specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3700191138300726"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with a mask for test image 3\n",
    "test_img_mask = cv.imread('DNN4SIM_data/sim_test_img_3_mask.png', cv.IMREAD_UNCHANGED)\n",
    "ssim(test_label[test_img_mask==255], test_wf[test_img_mask==255])\n",
    "#ssim(test_label, test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate test image 5\n",
    "img = rescale_img(cv.imread(f'DNN4SIM_data/DIV2K/0170.png', cv.IMREAD_GRAYSCALE))\n",
    "img = img[:1024,:1024]\n",
    "cv.imwrite('sim_test_img_5.png', img*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb679df05db4f9aa8680053aa87f948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b08cd58f3b44d8b16c889ba2f3f755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 'Images and FTs' figure\n",
    "orig_FT = apply_fft(test_orig);\n",
    "test_feature_lim = rescale_img(test_feature, lim=0.4)\n",
    "test_wf_lim = rescale_img(test_wf, lim=0.6)\n",
    "net_output_FT = apply_fft(net_output);\n",
    "img_list = [test_orig, test_label, test_feature_lim, net_output, test_wf_lim, orig_FT, label_FT, feature_FT, net_output_FT, wf_FT]\n",
    "img_names = ['Original DIV2K', 'Ground-Truth', 'Reconstruction', 'Net Output', 'Widefield', 'Original FT', 'Ground-Truth FT', 'Reconstruction FT', 'Net Output FT', 'Widefield FT']\n",
    "plt.close('all')\n",
    "view = viewer(img_list, title=img_names, subplots=(2,4), cmap='viridis', joint_zoom=True)\n",
    "view.fig.set_size_inches(8,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different model SNR directly\n",
    "The following cells load and compare multiple DNNs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the DNNs\n",
    "model_snrs = ['MIX', 'MIX2', 'MIX3']\n",
    "id_ = 'RCAN_custom_16_84_4'\n",
    "# Specify the test image and SNR\n",
    "test_img = 'sim_test_img_2'\n",
    "test_img_snr = 20\n",
    "\n",
    "# Load test images\n",
    "test_feature = rescale_img(cv.imread(f'DNN4SIM_data/{test_img}_recons_snr{test_img_snr}.png', cv.IMREAD_GRAYSCALE))\n",
    "test_wf = rescale_img(cv.imread(f'DNN4SIM_data/{test_img}_wf_snr{test_img_snr}.png', cv.IMREAD_GRAYSCALE))\n",
    "test_label = rescale_img(apply_rosette(cv.imread(f'DNN4SIM_data/{test_img}.png', cv.IMREAD_GRAYSCALE), rosette_1024))\n",
    "\n",
    "# Normalize images\n",
    "test_feature_processed = process_img(test_feature)\n",
    "test_wf_processed = process_img(test_wf)\n",
    "test_label_processed = process_img(test_label)\n",
    "\n",
    "net_outputs = []\n",
    "# Generate DNN outputs for all models\n",
    "for snr in model_snrs:\n",
    "    loss_id = f'snr{snr}_{id_}'\n",
    "    # Load corresponding model\n",
    "    model = RCAN(n_feats=64, n_resgroups=3, n_resblocks=5, reduction=16)\n",
    "    model.load_state_dict(torch.load(f'DNN4SIM_data/train_out/trained_model_{loss_id}.pt', map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    net_outputs.append(rescale_img(np.squeeze(model(torch.FloatTensor(test_feature_processed).unsqueeze(dim=0).unsqueeze(dim=0)).detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e758aedafc54c30a1c3c280c94c7a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b9c04d89d94620933818f8c2cae9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify zoom region\n",
    "#x1=0;y1=0;x2=1024;y2=1024 # Full image\n",
    "\n",
    "#x1=633;y1=863;x2=783;y2=1013 # test_img_3_cross\n",
    "#x1=9;y1=890;x2=138;y2=1019 # test_img_3_circle\n",
    "\n",
    "x1=372;y1=376;x2=522;y2=526 # test_img_2\n",
    "#x1=360;y1=660;x2=510;y2=810 # test_img_4\n",
    "\n",
    "# Visual comparison\n",
    "img_list = [test_label[y1:y2, x1:x2], test_wf[y1:y2, x1:x2], test_feature[y1:y2, x1:x2]] + [x[y1:y2, x1:x2] for x in net_outputs]\n",
    "output_names = [f'Net output snr{snr}' for snr in model_snrs]\n",
    "title_list = ['Ground-Truth', f'Widefield snr{test_img_snr}', f'Reconstruction snr{test_img_snr}'] + output_names\n",
    "plt.close('all')\n",
    "view = viewer(img_list, title=title_list, subplots=(2,3), cmap='viridis', joint_zoom=True)\n",
    "view.fig.set_size_inches(9,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure\n",
    "view.fig.savefig(f'DNN4SIM_data/results_images/test_img_{test_img.split(\"_\")[-1]}_model_comp_snr{test_img_snr}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image has snr of 20.\n",
      "\n",
      "\t\t|   SSIM   |   PSNR   |   FRC    |\n",
      "--------------------------------------------------\n",
      "Reconstruction  |  0.6547  |  17.7983 |  0.3579  |\n",
      "Widefield       |  0.6735  |  19.0269 |  0.3167  |\n",
      "Output(snrMIX)\t|  0.8896  |  \u001b[91m24.1863\u001b[0m |  0.4810  |\n",
      "Output(snrMIX2)\t|  0.8800  |  22.3362 |  0.4779  |\n",
      "Output(snrMIX3)\t|  \u001b[91m0.9000\u001b[0m  |  22.6938 |  \u001b[91m0.4821\u001b[0m  |\n"
     ]
    }
   ],
   "source": [
    "# Print metrics\n",
    "print(f'Test image has snr of {test_img_snr}.\\n' + \n",
    "      f'\\n\\t\\t|   SSIM   |   PSNR   |   FRC    |\\n' + 50*'-' + \n",
    "      f'\\nReconstruction  |  {ssim(test_feature, test_label):.4f}  |  {PSNR(test_feature, test_label):.4f} |  {compute_frc(test_label, test_feature)[1]:.4f}  |' + \n",
    "      f'\\nWidefield       |  {ssim(test_wf, test_label):.4f}  |  {PSNR(test_wf, test_label):.4f} |  {compute_frc(test_label, test_wf)[1]:.4f}  |')\n",
    "ssims = [ssim(test_label, net_outputs[i]) for i in range(len(model_snrs))]\n",
    "psnrs = [PSNR(test_label, net_outputs[i]) for i in range(len(model_snrs))]\n",
    "frcs = [compute_frc(test_label, net_outputs[i])[1] for i in range(len(model_snrs))]\n",
    "ssim_max = np.where(ssims == np.max(ssims))\n",
    "psnr_max = np.where(psnrs == np.max(psnrs))\n",
    "frcs_max = np.where(frcs == np.max(frcs))\n",
    "for i in range(len(model_snrs)):\n",
    "    print(f'Output(snr{model_snrs[i]})\\t|  {bcolors.FAIL if i in ssim_max[0] else \"\"}{ssims[i]:.4f}{bcolors.ENDC if i in ssim_max[0] else \"\"}  |  {bcolors.FAIL if i in psnr_max[0] else \"\"}{psnrs[i]:.4f}{bcolors.ENDC if i in psnr_max[0] else \"\"} |  {bcolors.FAIL if i in frcs_max[0] else \"\"}{frcs[i]:.4f}{bcolors.ENDC if i in frcs_max[0] else \"\"}  |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different image SNRs\n",
    "The following cells compare different test images and different DNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify test image snrs\n",
    "img_snrs = [5, 10, 15, 20]\n",
    "# Specify DNN names\n",
    "ids_ = ['MIX_RCAN_custom_16_84_4', 'MIX2_RCAN_custom_16_84_4', 'MIX3_RCAN_custom_16_84_4']\n",
    "# Specify test image\n",
    "test_img = 'sim_test_img_4'\n",
    "\n",
    "net_outputs = []\n",
    "test_features = []\n",
    "test_wfs = []\n",
    "test_label = rescale_img(apply_rosette(cv.imread(f'DNN4SIM_data/{test_img}.png', cv.IMREAD_GRAYSCALE), rosette_1024))\n",
    "test_label_processed = process_img(test_label)\n",
    "\n",
    "for i, test_img_snr in enumerate(img_snrs):\n",
    "    test_features.append(rescale_img(cv.imread(f'DNN4SIM_data/{test_img}_recons_snr{test_img_snr}.png', cv.IMREAD_GRAYSCALE)))\n",
    "    test_wfs.append(rescale_img(cv.imread(f'DNN4SIM_data/{test_img}_wf_snr{test_img_snr}.png', cv.IMREAD_GRAYSCALE)))\n",
    "\n",
    "    test_feature_processed = process_img(test_features[i])\n",
    "    test_wf_processed = process_img(test_wfs[i])\n",
    "    outputs = []\n",
    "    for id_ in ids_:\n",
    "        # Load corresponding model\n",
    "        model = RCAN(n_feats=64, n_resgroups=3, n_resblocks=5, reduction=16)\n",
    "        model.load_state_dict(torch.load(f'DNN4SIM_data/train_out/trained_model_snr{id_}.pt', map_location=torch.device('cpu')))\n",
    "        model.eval()\n",
    "        outputs.append(rescale_img(np.squeeze(model(torch.FloatTensor(test_feature_processed).unsqueeze(dim=0).unsqueeze(dim=0)).detach().numpy())))\n",
    "    net_outputs.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate FRC graphs\n",
    "frcs_out = []\n",
    "for j in range(len(ids_)):\n",
    "    frcs_out.append([compute_frc(test_label, net_outputs[i][j])[0] for i in range(len(img_snrs))])\n",
    "frcs_wf = [compute_frc(test_label, test_wfs[i])[0] for i in range(len(img_snrs))]\n",
    "frcs_recons = [compute_frc(test_label, test_features[i])[0] for i in range(len(img_snrs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8467d0731bc64f4281ded54564deda27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot them\n",
    "x = np.linspace(0, np.pi, len(frcs_wf[0]))\n",
    "plt.close('all'); fig = plt.figure(figsize=(8,6))\n",
    "out_names = ['snr' + s.split('_')[0] for s in ids_]\n",
    "for i in range(len(frcs_wf)):\n",
    "    ax1 = fig.add_subplot(2,2,i+1)\n",
    "    ax2 = ax1.twiny()\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax1.plot(x, frcs_wf[i])\n",
    "    ax1.plot(x, frcs_recons[i])\n",
    "    for j in range(len(ids_)):\n",
    "        ax1.plot(x, frcs_out[j][i])\n",
    "    ax1.legend(['wf', 'recons'] + out_names)\n",
    "    ax1.set_xlabel('Fourier ring radius [rad]'); ax1.set_ylabel('Correlation')\n",
    "    ax1.set_title(f'FRC snr{img_snrs[i]}')\n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    f = lambda j: 1//j\n",
    "    ax2.set_xticks(np.linspace(0, 3, 7))\n",
    "    ax2.set_xticklabels(f(np.linspace(1/(32*1024),1/64,7)).astype(int))\n",
    "    ax2.set_xlabel('Feature size [nm]')\n",
    "    fig.tight_layout()\n",
    "    ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figure as png and .pkl for possible changes\n",
    "with open(f'DNN4SIM_data/results_images/{\"_\".join(test_img.split(\"_\")[1:4])}_comp_frc.pkl','wb') as fid:\n",
    "    pickle.dump(fig, fid)\n",
    "fig.savefig(f'DNN4SIM_data/results_images/{\"_\".join(test_img.split(\"_\")[1:4])}_comp_frc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a .pkl figure\n",
    "plt.close('all')\n",
    "with open('test_figure.pkl','rb') as fid:\n",
    "    fig = pickle.load(fid)\n",
    "axs = fig.axes\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f83475e014046c7a49e8888d597f334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = (920, 640); p2 = (920, 800) # horizontal over cross and thin lines\n",
    "#p1 = (1008, 75); p2 = (958, 116) # ascending diagonal of smallest circle\n",
    "snr_idx = 3\n",
    "img_list = [test_label, test_wfs[snr_idx], test_features[snr_idx]] + [net_outputs[snr_idx][id_] for id_ in range(len(ids_))]\n",
    "title_list = ['Ground-Truth', f'Widefield snr{img_snrs[snr_idx]}', f'Reconstruction snr{img_snrs[snr_idx]}'] + [f'Net Output snr{ids_[i].split(\"_\")[0]}' for i in range(len(ids_))]\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in range(len(img_list)):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.title(title_list[i])\n",
    "    plt.plot(get_line(img_list[i], p1, p2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used model: MIX3_RCAN_custom_16_84_4.\n",
      "\n",
      "Outputs\t\t|   SSIM   |   PSNR   |   FRC    |\n",
      "--------------------------------------------------\n",
      "Output (snr5)\t|  0.8388  |  16.9308 |  0.4848  |\n",
      "Output (snr10)\t|  0.8855  |  17.3770 |  \u001b[91m0.5281\u001b[0m  |\n",
      "Output (snr15)\t|  \u001b[91m0.8934\u001b[0m  |  18.4570 |  0.5256  |\n",
      "Output (snr20)\t|  0.8836  |  \u001b[91m19.0051\u001b[0m |  0.5089  |\n"
     ]
    }
   ],
   "source": [
    "print(f'Used model: {id_}.\\n' + \n",
    "      f'\\nOutputs\\t\\t|   SSIM   |   PSNR   |   FRC    |\\n' + 50*'-')\n",
    "\n",
    "ssims = [ssim(test_label, net_outputs[0][i]) for i in range(len(img_snrs))]\n",
    "psnrs = [PSNR(test_label, net_outputs[0][i]) for i in range(len(img_snrs))]\n",
    "frcs = [compute_frc(test_label, net_outputs[i])[1] for i in range(len(img_snrs))]\n",
    "ssim_max = np.where(ssims == np.max(ssims))\n",
    "psnr_max = np.where(psnrs == np.max(psnrs))\n",
    "frcs_max = np.where(frcs == np.max(frcs))\n",
    "for i in range(len(img_snrs)):\n",
    "    print(f'Output (snr{img_snrs[i]})\\t|  {bcolors.FAIL if i in ssim_max[0] else \"\"}{ssims[i]:.4f}{bcolors.ENDC if i in ssim_max[0] else \"\"}  |  {bcolors.FAIL if i in psnr_max[0] else \"\"}{psnrs[i]:.4f}{bcolors.ENDC if i in psnr_max[0] else \"\"} |  {bcolors.FAIL if i in frcs_max[0] else \"\"}{frcs[i]:.4f}{bcolors.ENDC if i in frcs_max[0] else \"\"}  |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used model: MIX_RCAN_custom_16_84_4.\n",
      "\n",
      "Reconstructions\t|   SSIM   |   PSNR   |   FRC    |\n",
      "--------------------------------------------------\n",
      "Recons (snr5)\t|  0.2709  |  10.9715 |  0.2347  |\n",
      "Recons (snr10)\t|  0.3610  |  12.2567 |  0.3055  |\n",
      "Recons (snr15)\t|  0.4199  |  13.3106 |  0.3557  |\n",
      "Recons (snr20)\t|  \u001b[91m0.4389\u001b[0m  |  \u001b[91m13.8177\u001b[0m |  \u001b[91m0.3871\u001b[0m  |\n"
     ]
    }
   ],
   "source": [
    "print(f'Used model: {id_}.\\n' + \n",
    "      f'\\nReconstructions\\t|   SSIM   |   PSNR   |   FRC    |\\n' + 50*'-')\n",
    "\n",
    "ssims = [ssim(test_label, test_features[i]) for i in range(len(img_snrs))]\n",
    "psnrs = [PSNR(test_label, test_features[i]) for i in range(len(img_snrs))]\n",
    "frcs = [compute_frc(test_label, test_features[i])[1] for i in range(len(img_snrs))]\n",
    "ssim_max = np.where(ssims == np.max(ssims))\n",
    "psnr_max = np.where(psnrs == np.max(psnrs))\n",
    "frcs_max = np.where(frcs == np.max(frcs))\n",
    "for i in range(len(img_snrs)):\n",
    "    print(f'Recons (snr{img_snrs[i]})\\t|  {bcolors.FAIL if i in ssim_max[0] else \"\"}{ssims[i]:.4f}{bcolors.ENDC if i in ssim_max[0] else \"\"}  |  {bcolors.FAIL if i in psnr_max[0] else \"\"}{psnrs[i]:.4f}{bcolors.ENDC if i in psnr_max[0] else \"\"} |  {bcolors.FAIL if i in frcs_max[0] else \"\"}{frcs[i]:.4f}{bcolors.ENDC if i in frcs_max[0] else \"\"}  |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used model: MIX_RCAN_custom_16_84_4.\n",
      "\n",
      "Widefields\t|   SSIM   |   PSNR   |   FRC    |\n",
      "--------------------------------------------------\n",
      "Wf (snr5)\t|  0.2914  |  11.4231 |  0.2772  |\n",
      "Wf (snr10)\t|  \u001b[91m0.3081\u001b[0m  |  \u001b[91m11.5218\u001b[0m |  0.3170  |\n",
      "Wf (snr15)\t|  0.2978  |  11.4683 |  0.3412  |\n",
      "Wf (snr20)\t|  0.2829  |  11.3833 |  \u001b[91m0.3602\u001b[0m  |\n"
     ]
    }
   ],
   "source": [
    "print(f'Used model: {id_}.\\n' + \n",
    "      f'\\nWidefields\\t|   SSIM   |   PSNR   |   FRC    |\\n' + 50*'-')\n",
    "\n",
    "ssims = [ssim(test_label, test_wfs[i]) for i in range(len(img_snrs))]\n",
    "psnrs = [PSNR(test_label, test_wfs[i]) for i in range(len(img_snrs))]\n",
    "frcs = [compute_frc(test_label, test_wfs[i])[1] for i in range(len(img_snrs))]\n",
    "ssim_max = np.where(ssims == np.max(ssims))\n",
    "psnr_max = np.where(psnrs == np.max(psnrs))\n",
    "frcs_max = np.where(frcs == np.max(frcs))\n",
    "for i in range(len(img_snrs)):\n",
    "    print(f'Wf (snr{img_snrs[i]})\\t|  {bcolors.FAIL if i in ssim_max[0] else \"\"}{ssims[i]:.4f}{bcolors.ENDC if i in ssim_max[0] else \"\"}  |  {bcolors.FAIL if i in psnr_max[0] else \"\"}{psnrs[i]:.4f}{bcolors.ENDC if i in psnr_max[0] else \"\"} |  {bcolors.FAIL if i in frcs_max[0] else \"\"}{frcs[i]:.4f}{bcolors.ENDC if i in frcs_max[0] else \"\"}  |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRC experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e286683b00046868ffc22afbf1c03ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frc = compute_frc(test_label, test_wf)\n",
    "frc_2 = compute_frc(test_label, net_outputs[3])\n",
    "frc_rec = compute_frc(test_label, test_feature)\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "pixel_res = 32\n",
    "x = np.linspace(0,1/(2*pixel_res),len(frc[0]))\n",
    "plt.ylim([0,1])\n",
    "plt.plot(x, frc[0])\n",
    "plt.plot(x, frc_2[0])\n",
    "plt.plot(x, frc_rec[0])\n",
    "plt.legend(['wf', 'output', 'recons'])\n",
    "plt.title(f'FRC wf'); plt.xlabel('$nm^{-1}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ['RCAN_ssim_4', 'RCAN_sL1_4', 'RCAN_custom_16_84_4']\n",
    "snr = 5\n",
    "test_img = 'sim_test_img_3'\n",
    "test_img_snr = snr\n",
    "\n",
    "test_feature = rescale_img(cv.imread(f'DNN4SIM_data/{test_img}_recons_snr{test_img_snr}.png', cv.IMREAD_GRAYSCALE))\n",
    "test_wf = rescale_img(cv.imread(f'DNN4SIM_data/{test_img}_wf_snr{test_img_snr}.png', cv.IMREAD_GRAYSCALE))\n",
    "test_label = rescale_img(apply_rosette(cv.imread(f'DNN4SIM_data/{test_img}.png', cv.IMREAD_GRAYSCALE), rosette_1024))\n",
    "\n",
    "test_feature_processed = process_img(test_feature)\n",
    "test_wf_processed = process_img(test_wf)\n",
    "test_label_processed = process_img(test_label)\n",
    "\n",
    "net_outputs = []\n",
    "\n",
    "for id_ in ids:\n",
    "    loss_id = f'snr{snr}_{id_}'\n",
    "    # Load corresponding model\n",
    "    model = RCAN(n_feats=64, n_resgroups=3, n_resblocks=5, reduction=16)\n",
    "    model.load_state_dict(torch.load(f'DNN4SIM_data/train_out/trained_model_{loss_id}.pt', map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    net_outputs.append(rescale_img(np.squeeze(model(torch.FloatTensor(test_feature_processed).unsqueeze(dim=0).unsqueeze(dim=0)).detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image has snr of 5.\n",
      "\n",
      "\t\t|   SSIM   |   PSNR   |   FRC    |\n",
      "--------------------------------------------------\n",
      "Reconstruction  |  0.2709  |  10.9715 |  0.0652  |\n",
      "Widefield       |  0.2914  |  11.4231 |  0.1728  |\n",
      "Output (RCAN_ssim_4)\t|  0.7333  |  \u001b[91m18.6146\u001b[0m |  0.2068  |\n",
      "Output (RCAN_sL1_4)\t|  \u001b[91m0.8398\u001b[0m  |  17.6279 |  \u001b[91m0.2380\u001b[0m  |\n",
      "Output (RCAN_custom_16_84_4)\t|  0.8338  |  17.9102 |  \u001b[91m0.2380\u001b[0m  |\n"
     ]
    }
   ],
   "source": [
    "print(f'Test image has snr of {test_img_snr}.\\n' + \n",
    "      f'\\n\\t\\t|   SSIM   |   PSNR   |   FRC    |\\n' + 50*'-' + \n",
    "      f'\\nReconstruction  |  {ssim(test_feature, test_label):.4f}  |  {PSNR(test_feature, test_label):.4f} |  {compute_frc(test_label, test_feature)[1]:.4f}  |' + \n",
    "      f'\\nWidefield       |  {ssim(test_wf, test_label):.4f}  |  {PSNR(test_wf, test_label):.4f} |  {compute_frc(test_label, test_wf)[1]:.4f}  |')\n",
    "\n",
    "net_outputs[0] = 1-net_outputs[0]\n",
    "\n",
    "ssims = [ssim(test_label, net_outputs[i]) for i in range(len(ids))]\n",
    "psnrs = [PSNR(test_label, net_outputs[i]) for i in range(len(ids))]\n",
    "frcs = [compute_frc(test_label, net_outputs[i])[1] for i in range(len(ids))]\n",
    "ssim_max = np.where(ssims == np.max(ssims))\n",
    "psnr_max = np.where(psnrs == np.max(psnrs))\n",
    "frcs_max = np.where(frcs == np.max(frcs))\n",
    "for i in range(len(ids)):\n",
    "    print(f'Output ({ids[i]})\\t|  {bcolors.FAIL if i in ssim_max[0] else \"\"}{ssims[i]:.4f}{bcolors.ENDC if i in ssim_max[0] else \"\"}  |  {bcolors.FAIL if i in psnr_max[0] else \"\"}{psnrs[i]:.4f}{bcolors.ENDC if i in psnr_max[0] else \"\"} |  {bcolors.FAIL if i in frcs_max[0] else \"\"}{frcs[i]:.4f}{bcolors.ENDC if i in frcs_max[0] else \"\"}  |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5343a15afbc14179a817c3831694f499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1efd580fd54194bc40e0daf4124cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_list = [test_label, test_wf, test_feature] + net_outputs\n",
    "output_names = [f'Net output {id_}' for id_ in ids]\n",
    "title_list = ['Ground-Truth', f'Widefield snr{test_img_snr}', f'Reconstruction snr{test_img_snr}'] + output_names\n",
    "plt.close('all')\n",
    "view = viewer(img_list, title=title_list, subplots=(2,3), cmap='viridis', joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RCAN(\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (0): ResidualGroup(\n",
       "      (body): Sequential(\n",
       "        (0): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualGroup(\n",
       "      (body): Sequential(\n",
       "        (0): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualGroup(\n",
       "      (body): Sequential(\n",
       "        (0): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): RCAB(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): CALayer(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (conv_du): Sequential(\n",
       "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (tail): Sequential(\n",
       "    (0): Upsampler()\n",
       "    (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_id = 'snr20_RCAN_custom_16_84'\n",
    "structure = 'RCAN'\n",
    "model = None\n",
    "if structure == 'RCAN':\n",
    "    model = RCAN(n_feats=64, n_resgroups=3, n_resblocks=5, reduction=16)\n",
    "else:\n",
    "    model = CUNet()\n",
    "model.load_state_dict(torch.load(f'DNN4SIM_data/train_out/trained_model_{loss_id}.pt', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fft(img):\n",
    "    FT = np.abs(np.fft.fftshift(np.fft.fft2(img)))\n",
    "    FT[FT == 0] = 1e-5\n",
    "    return 10*np.log10(FT)\n",
    "\n",
    "def process_img(img):\n",
    "    return (img - np.mean(img)) / np.std(img)\n",
    "\n",
    "def rescale_img(img):\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    return img.astype(np.float64)\n",
    "\n",
    "def snr(img):\n",
    "    m = np.mean(img)\n",
    "    sd = np.std(img)\n",
    "    return 10*np.log10(m/sd)\n",
    "\n",
    "def stretch_contrast(img, c=0.03):\n",
    "    return exposure.equalize_adapthist(img, clip_limit=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 253\n",
    "feature = features[n]\n",
    "label = rescale_img(labels[n])\n",
    "wf = rescale_img(wfs[n])\n",
    "\n",
    "if structure == 'RCAN':\n",
    "    net_output = rescale_img(np.squeeze(depatchify(model(patchify(feature, 256))).detach().numpy()))\n",
    "else:\n",
    "    net_output = rescale_img(np.squeeze(model(torch.FloatTensor(feature).unsqueeze(dim=0).unsqueeze(dim=0)).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM:\tReconstruction: 0.6084\n",
      "\tNet output: \t0.8978\n",
      "\tWidefield: \t0.6669\n",
      "SNR:\tReconstruction: 4.6805\n",
      "\tNet output: \t5.3567\n",
      "\tWidefield: \t5.0658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34016b7544e941098c81e4eb908e9ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f159f273314f7ba7d60f59f8b8d1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With FT\n",
    "\n",
    "#label_FT = apply_fft(label); feature_FT = apply_fft(feature); net_output_FT = apply_fft(net_output)\n",
    "#img_list = [feature, net_output, feature_FT, net_output_FT]\n",
    "\n",
    "# For img 253\n",
    "#feature = feature[770:1024, 575:829]; label = label[770:1024, 575:829]; wf = wf[770:1024, 575:829]; net_output = net_output[770:1024, 575:829]\n",
    "\n",
    "# Without wf / without FT\n",
    "img_list = [rescale_img(feature), label, net_output, wf]\n",
    "#img_list = [stretch_contrast(img) for img in img_list]\n",
    "\n",
    "# Stats\n",
    "print(f'SSIM:\\tReconstruction: {ssim(rescale_img(feature), label):.4f}\\n\\tNet output: \\t{ssim(net_output, label):.4f}\\n\\tWidefield: \\t{ssim(wf, label):.4f}')\n",
    "print(f'SNR:\\tReconstruction: {snr(rescale_img(feature)):.4f}\\n\\tNet output: \\t{snr(net_output):.4f}\\n\\tWidefield: \\t{snr(wf):.4f}')\n",
    "\n",
    "plt.close('all')\n",
    "title_list = ['Reconstruction', 'Ground-Truth', 'Net Output', 'Widefield']\n",
    "view = viewer(img_list, title=title_list, subplots=(2,2), cmap='viridis', joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Showcase Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Widefield image is not in [0,1]\n",
    "wf = wf-np.min(wf)\n",
    "# Colorize images\n",
    "feature_colorized = cv.applyColorMap((feature*255).astype(np.uint8), cv.COLORMAP_VIRIDIS)\n",
    "wf_colorized = cv.applyColorMap((wf*255).astype(np.uint8), cv.COLORMAP_VIRIDIS)\n",
    "label_colorized = cv.applyColorMap((label*255).astype(np.uint8), cv.COLORMAP_VIRIDIS)\n",
    "net_output_colorized = cv.applyColorMap((net_output*255).astype(np.uint8), cv.COLORMAP_VIRIDIS)\n",
    "\n",
    "loss_id = 'L1'\n",
    "# Save images\n",
    "cv.imwrite(f'showcase/feature_{loss_id}.png', feature_colorized)\n",
    "cv.imwrite(f'showcase/wf_{loss_id}.png', wf_colorized)\n",
    "cv.imwrite(f'showcase/label_{loss_id}.png', label_colorized)\n",
    "cv.imwrite(f'showcase/net_output_{loss_id}.png', net_output_colorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rosette tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosette_512 = np.load('DNN4SIM_data/rosette_512.npy')\n",
    "rosette_1024 = np.load('DNN4SIM_data/rosette_1024.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rosette(img, rosette):\n",
    "    FT = np.fft.fftshift(np.fft.fft2(img))\n",
    "    FT[rosette == 0] = 1e-5\n",
    "    return np.real(np.fft.ifft2(np.fft.ifftshift(FT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1c38cd165a46ce9f06e3f94aac10e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<iplabs.IPLabViewer at 0x178e8ad2e88>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = apply_rosette(label, rosette_1024)\n",
    "l = (l - np.min(l)) / (np.max(l) - np.min(l))\n",
    "l_ft = apply_fft(l)\n",
    "f = feature\n",
    "f_ft = apply_fft(f)\n",
    "plt.close('all')\n",
    "viewer([f, l, f_ft, l_ft], subplots=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS-SSIM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(output, target):\n",
    "    ssim_loss = MS_SSIM(data_range=1.0, size_average=True, channel=1)\n",
    "    sl1l = F.smooth_l1_loss\n",
    "    return 0.16 * sl1l(output, target) + 0.84 * (1 - ssim_loss(output, target))\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    return ssim(outputs, labels, data_range=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5339216589927673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5550482273101807"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "X = torch.FloatTensor(wf).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "Y = torch.FloatTensor(label).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "\n",
    "print(accuracy(X, Y).item())\n",
    "ssim_acc = pytorch_ssim.SSIM()\n",
    "ssim_acc(X, Y).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
