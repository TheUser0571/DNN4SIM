{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nd2reader import ND2Reader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, 'lib')\n",
    "from iplabs import IPLabViewer as viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIM Input images\n",
    "\n",
    "There are **120** raw images, each containing **3** channels. This results in a total of **360** different raw images that can be used as inputs. This number can be increased by a factor of two by rotating the images $180^{\\circ}$, which leaves us with a **total of 720 input-output pairs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_input = ND2Reader('DNN4SIM_data/data/raw/Image001/SIM_input.nd2')\n",
    "print('Metadata:\\n', sim_input.metadata)\n",
    "print('\\nSizes:\\n', sim_input.sizes)\n",
    "print('\\nNumber of rows (angles): ', sim_input.sizes['y'] / 512)\n",
    "print('Number of columns (phases): ', sim_input.sizes['x'] / 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_inputs = {}\n",
    "sim_input.iter_axes = 'c'\n",
    "for i, channel in enumerate(sim_input):\n",
    "    sim_inputs[sim_input.metadata['channels'][i]]= channel\n",
    "\n",
    "plt.close('all')\n",
    "view = viewer(list(sim_inputs.values()), title=list(sim_inputs.keys()), widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIM Output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_output = ND2Reader('DNN4SIM_data/data/raw/Image001/SIM_output.nd2')\n",
    "print('Metadata:\\n', sim_output.metadata)\n",
    "print('\\nSizes:\\n', sim_output.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_outputs = {}\n",
    "sim_output.iter_axes = 'c'\n",
    "for i, channel in enumerate(sim_output):\n",
    "    sim_outputs[sim_output.metadata['channels'][i]]= channel\n",
    "\n",
    "plt.close('all')\n",
    "view = viewer(list(sim_outputs.values()), title=list(sim_outputs.keys()), widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input phases exploration\n",
    "\n",
    "Which combination of phases and angles is best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_test = np.array(list(sim_inputs.values())[0])\n",
    "\n",
    "phase_test = phase_test[:512, :]\n",
    "\n",
    "phase_imgs = []\n",
    "width = 512\n",
    "for i in range(phase_test.shape[1] // width):\n",
    "    if i in [1, 3]:\n",
    "        phase_imgs.append(phase_test[:, i*width:(i+1)*width])\n",
    "    \n",
    "phase_imgs_avg = np.mean(phase_imgs, axis = 0)\n",
    "\n",
    "plt.close('all')\n",
    "view = viewer(phase_imgs_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "The only change that preserves the angle of the Structured Illumination is a **rotation by $180^{\\circ}$**. This means we can only increase the number of images by a factor of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp_test = np.array(list(sim_inputs.values())[0])[:512,:512]\n",
    "\n",
    "pps = [pp_test]\n",
    "pps_names = ['orig']\n",
    "for i in range(3):\n",
    "    pps.append(np.rot90(pps[i]))\n",
    "    pps_names.append(f'rot {int(90*(i+1))}')\n",
    "for i in range(4):\n",
    "    pps.append(np.flip(pps[i], axis = 0))\n",
    "    pps_names.append(f'rot {int(90*i)} flipped')\n",
    "    \n",
    "plt.close('all')\n",
    "view = viewer(pps, title=pps_names, subplots=(2, len(pps)//2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the illumination angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.fft as fft\n",
    "import skimage\n",
    "\n",
    "# Difference of Gaussian\n",
    "def dog(img, sigma1):\n",
    "    output = np.copy(img)\n",
    "    sigma2 = np.sqrt(2)*sigma1\n",
    "    filt1 = skimage.filters.gaussian(img, sigma = sigma1 , mode = 'reflect', truncate = 3, preserve_range = True)\n",
    "    filt2 = skimage.filters.gaussian(img, sigma = sigma2 , mode = 'reflect', truncate = 3, preserve_range = True)\n",
    "    output = filt1 - filt2\n",
    "    # normalize output\n",
    "    output = (output - np.min(output)) /(np.max(output) - np.min(output))\n",
    "    return output\n",
    "\n",
    "# Local max in a 3x3 nbh\n",
    "def local_max(img, T):\n",
    "    output = np.zeros(img.shape)\n",
    "    coord = skimage.feature.peak_local_max(img, min_distance=1, threshold_rel = T)\n",
    "    output[coord[:,0],coord[:,1]] = np.max(img)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "angle = 0\n",
    "phase = 3\n",
    "sig = 2\n",
    "T = 0.7\n",
    "\n",
    "img = np.array(list(sim_inputs.values())[channel])[angle*512:(angle+1)*512, phase*512:(phase+1)*512]\n",
    "\n",
    "# FFT in dB\n",
    "img_ft = 10 * np.log10(np.abs(fft.fftshift(fft.fft2(img))))\n",
    "\n",
    "# Detect spots\n",
    "img_ft_detect = dog(img_ft, sig)\n",
    "coords = skimage.feature.peak_local_max(img_ft_detect, min_distance=1, threshold_rel = T)\n",
    "print('Coords:\\n', coords)\n",
    "\n",
    "# Calculate angle\n",
    "if coords.shape[0] == 3:\n",
    "    print(f'\\nAngle: {(360 * np.arctan2(coords[2,0] - coords[1,0], coords[2,1] - coords[1,1]) / (2*np.pi)):.3f} deg')\n",
    "\n",
    "plt.close('all')\n",
    "img_ft_detect = local_max(img_ft_detect, T)\n",
    "view = viewer([img, img_ft, img_ft_detect], subplots=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illumination angles:\n",
    "* $\\alpha_1 = 13.815^{\\circ}$\n",
    "* $\\alpha_2 = 133.698^{\\circ}$\n",
    "* $\\alpha_3 = 254.181^{\\circ}$\n",
    "\n",
    "$\\Delta \\alpha \\approx 120^{\\circ}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nd2reader import ND2Reader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "# Print colors\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "# Load the sim_input image from 'path'\n",
    "def load_sim_input(path, phases=[0,1,2,3,4], angles=[0,1,2]):\n",
    "    sim_in = ND2Reader(path)\n",
    "    sim_ch = []\n",
    "    sim_in.iter_axes = 'c'\n",
    "    for channel in sim_in:\n",
    "        imgs = []\n",
    "        for angle in angles:\n",
    "            for phase in phases:\n",
    "                new_img = channel[angle*512:(angle+1)*512, phase*512:(phase+1)*512]\n",
    "                if len(imgs) > 0 and new_img.shape != imgs[-1].shape:\n",
    "                    print(f'{bcolors.FAIL}Size problem with file {path}, skipping this file.{bcolors.ENDC}')\n",
    "                    raise ValueError()\n",
    "                imgs.append(new_img)    \n",
    "        \n",
    "        sim_ch.append(np.array(imgs))\n",
    "        \n",
    "    \n",
    "    \n",
    "    return sim_ch\n",
    "\n",
    "# Load the sim_output image from 'path'\n",
    "def load_sim_output(path):\n",
    "    sim_in = ND2Reader(path)\n",
    "    sim_ch = []\n",
    "    sim_in.iter_axes = 'c'\n",
    "    for channel in sim_in:\n",
    "        if channel.shape != (1024,1024):\n",
    "            print(f'{bcolors.FAIL}Size problem with file {path}, skipping this file.{bcolors.ENDC}')\n",
    "            raise ValueError()\n",
    "        \n",
    "        sim_ch.append(np.array(channel))\n",
    "    \n",
    "    return sim_ch\n",
    "    \n",
    "# Load the entire sim dataset into a numpy array\n",
    "def load_sim_dataset(path_to_raw, phases=[0,1,2,3,4], angles=[0,1,2]):\n",
    "    ds = []\n",
    "    ls = []\n",
    "    path_to_raw = Path(path_to_raw)\n",
    "\n",
    "    # Loop through all image folders and add the sim images to the dataset\n",
    "    print('Collecting images...   0%', end='\\r')\n",
    "    subdir_list = [f for f in path_to_raw.glob('*')]\n",
    "    for i, f in enumerate(subdir_list):\n",
    "        # Input images\n",
    "        input_path = f / 'SIM_input.nd2'\n",
    "        try:\n",
    "            # Append images to data\n",
    "            ds = ds + load_sim_input(input_path, phases=phases, angles=angles)\n",
    "        except (FileNotFoundError, ValueError) as err:\n",
    "            if type(err) == FileNotFoundError:\n",
    "                print(f'{bcolors.FAIL}File missing: {input_path}{bcolors.ENDC}')\n",
    "                continue\n",
    "            elif type(err) == ValueError:\n",
    "                continue\n",
    "\n",
    "        # Output images\n",
    "        output_path = f / 'SIM_output.nd2'\n",
    "        try:\n",
    "            # Append images to labels\n",
    "            ls = ls + load_sim_output(output_path)\n",
    "        except (FileNotFoundError, ValueError) as err:\n",
    "            if type(err) == FileNotFoundError:\n",
    "                print(f'{bcolors.FAIL}File missing: {output_path}{bcolors.ENDC}')\n",
    "                ds.pop(-1)\n",
    "            elif type(err) == ValueError:\n",
    "                ds.pop(-1)\n",
    "        print(f'Collecting images... {i/len(subdir_list)*100:3.0f}%', end='\\r')\n",
    "    \n",
    "    print(f'Collecting images... {bcolors.OKGREEN}100%{bcolors.ENDC}')\n",
    "    # Check that data and labels have the same length\n",
    "    if len(ds) != len(ls):\n",
    "        raise ValueError('The data and labels are not of the same length.')\n",
    "    \n",
    "    # Create output dictionary\n",
    "    output = {'data' : np.array(ds), 'labels' : np.array(ls)}\n",
    "        \n",
    "    return output\n",
    "\n",
    "# Augment dataset (add a 180 degree rotated copy of the dataset and shuffle the result)\n",
    "def augment_dataset(ds):\n",
    "    skip = False\n",
    "    if skip is False:\n",
    "        # Normalize images\n",
    "        print('Normalizing images...   0%', end='\\r')\n",
    "        # Calculate min an max for data and labels\n",
    "        min_data = np.min(np.min(ds['data'], axis=-1), axis=-1)\n",
    "        max_data = np.max(np.max(ds['data'], axis=-1), axis=-1)\n",
    "        min_labels = np.min(np.min(ds['labels'], axis=-1), axis=-1)\n",
    "        max_labels = np.max(np.max(ds['labels'], axis=-1), axis=-1)\n",
    "        # Normalize all images to [0, 1]\n",
    "        data_length = ds['data'].shape[0]\n",
    "        ds_ = {'data' : ds['data'].copy().astype(np.float64), 'labels' : ds['labels'].copy().astype(np.float32)}\n",
    "        for i in range(data_length):\n",
    "            for j in range(ds['data'].shape[1]):\n",
    "                ds_['data'][i][j] = (ds['data'][i][j].astype(np.float64) - min_data[i][j]) / (max_data[i][j] - min_data[i][j])\n",
    "            ds_['labels'][i] = (ds['labels'][i].astype(np.float64) - min_labels[i]) / (max_labels[i] - min_labels[i])\n",
    "            print(f'Normalizing images... {i/data_length*100:3.0f}%', end='\\r')\n",
    "\n",
    "        print(f'Normalizing images... {bcolors.OKGREEN}100%{bcolors.ENDC}')\n",
    "    # Rotate images\n",
    "    print('Augmenting dataset...', end='\\r')\n",
    "    # Create new dataset with rotated images and labels\n",
    "    ds_['data'] = np.concatenate((ds_['data'], np.rot90(ds_['data'], k=2, axes=(2,3))))\n",
    "    ds_['labels'] = np.concatenate((ds_['labels'], np.rot90(ds_['labels'], k=2, axes=(1,2))))\n",
    "    print(f'Augmenting dataset... {bcolors.OKGREEN}Done{bcolors.ENDC}')\n",
    "    # Shuffle the dataset\n",
    "    print('Shuffling dataset...', end='\\r')\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(ds_['data'].shape[0])\n",
    "    ds_['data'] = ds_['data'][idx]\n",
    "    ds_['labels'] = ds_['labels'][idx]\n",
    "    print(f'Shuffling dataset... {bcolors.OKGREEN}Done{bcolors.ENDC}')\n",
    "    \n",
    "    return ds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images...   0%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay-1\\Anaconda3\\envs\\DNN4SIM_env\\lib\\site-packages\\nd2reader\\raw_metadata.py:171: UserWarning: Z-levels details missing in metadata. Using Z-coordinates instead.\n",
      "  warnings.warn(\"Z-levels details missing in metadata. Using Z-coordinates instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mSize problem with file DNN4SIM_data\\data\\raw\\Image029\\SIM_input.nd2, skipping this file.\u001b[0m\n",
      "\u001b[91mFile missing: DNN4SIM_data\\data\\raw\\Image056\\SIM_input.nd2\u001b[0m\n",
      "\u001b[91mFile missing: DNN4SIM_data\\data\\raw\\Image057\\SIM_input.nd2\u001b[0m\n",
      "\u001b[91mFile missing: DNN4SIM_data\\data\\raw\\Image094\\SIM_input.nd2\u001b[0m\n",
      "Collecting images... \u001b[92m100%\u001b[0m\n",
      "\u001b[92mFinished loading dataset.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#dataset = load_sim_dataset('DNN4SIM_data/data/raw')\n",
    "dataset = load_sim_dataset('DNN4SIM_data/data/raw', phases=[1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing images... \u001b[92m100%\u001b[0m\n",
      "Augmenting dataset... \u001b[92mDone\u001b[0m\n",
      "Shuffling dataset... \u001b[92mDone\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "aug_dataset = augment_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  (696, 6, 512, 512)\n",
      "Labels:  (696, 1024, 1024)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc01fd4c34cd4ca2a2cbf2e036cfa03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ebf19660cb489aa6a54a3b21c07309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<iplabs.IPLabViewer at 0x21a7b4a76a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Data: ', aug_dataset['data'].shape)\n",
    "print('Labels: ', aug_dataset['labels'].shape)\n",
    "\n",
    "# Show a random collection of 5 images and their corresponding labels\n",
    "r_0 = np.random.randint(0, aug_dataset['data'].shape[0], 5)\n",
    "r_1 = np.random.randint(0, aug_dataset['data'].shape[1], 5)\n",
    "img_list = []\n",
    "img_names = []\n",
    "for i in range(len(r_0)):\n",
    "    img_list.append(aug_dataset['data'][r_0[i]][r_1[i]])\n",
    "    img_names.append('data')\n",
    "for i in range(len(r_0)):\n",
    "    img_list.append(aug_dataset['labels'][r_0[i]])\n",
    "    img_names.append('label')\n",
    "\n",
    "plt.close('all')\n",
    "viewer(img_list, title=img_names, subplots=(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 8.69111768e-05, 2.60733530e-04, ...,\n",
       "       9.03963150e-01, 9.67929776e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(aug_dataset['data'][2][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cell_type', 'metadata', 'source'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('Filtering.ipynb') as nb:\n",
    "    d = json.load(nb)\n",
    "    print(d['cells'][0].keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
